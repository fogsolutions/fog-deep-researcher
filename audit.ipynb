{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Specify the path to your local model or the model name from Hugging Face\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "# Initialize the Hugging Face embeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z9/rcc6fb195dnclys6htg1vv_w0000gn/T/ipykernel_72664/3279522036.py:16: LangChainDeprecationWarning: The class `UnstructuredFileLoader` was deprecated in LangChain 0.2.8 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-unstructured package and should be used instead. To use it run `pip install -U :class:`~langchain-unstructured` and import as `from :class:`~langchain_unstructured import UnstructuredLoader``.\n",
      "  loader = UnstructuredFileLoader(document_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ./my-docs/Amynta Group - Solution Design.docx\n",
      "Loaded ./my-docs/Broker In A Box/Broker in a Box - Exec Overview (01-21-2025).pptx\n",
      "Loaded ./my-docs/Broker In A Box/AP_Rules.xlsx\n",
      "Loaded ./my-docs/Broker In A Box/AP_Rule_Evalution_test1.docx\n",
      "Loaded ./my-docs/Broker In A Box/Assured Partners - Broker in a Box - Endorsements - Proposed Solution Overview - 01292025.pptx\n",
      "Loaded ./my-docs/Broker In A Box/Proposal & Contracts/Broker In A Box Change Request#2 1.14.25 - SOW - AP Format.docx\n",
      "Loaded ./my-docs/Broker In A Box/Proposal & Contracts/Fog Solutions - Assured Partners - Broker in a Box - Proposal.pptx\n",
      "Loaded ./my-docs/Broker In A Box/Proposal & Contracts/SOW_3060310_Fog Solutions Inc._CAS-1477383-D1Q5K3_267970094 - signed.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Proposal & Contracts/AssuredPartners - Fog Solutions - Broker in a Box - Exhibit A.docx\n",
      "Loaded ./my-docs/Broker In A Box/Proposal & Contracts/ECIF PO 101108580 AssuredPartners.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Proposal & Contracts/AssuredPartners - Fog Solutions - Broker in a Box - AP Formated SOW - Fully Executed.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Proposal & Contracts/Broker In A Box Change Request SOW - AP Format (002) - Fully executed.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Proposal & Contracts/OLD Fog Solutions -Assured Partners - Broker in a Box - Estimation Worksheet.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinbooth/fog/gpt-researcher/.venv/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/Users/kevinbooth/fog/gpt-researcher/.venv/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/Users/kevinbooth/fog/gpt-researcher/.venv/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/Users/kevinbooth/fog/gpt-researcher/.venv/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ./my-docs/Broker In A Box/Proposal & Contracts/Broker In A Box Change Request #2 1.23.25 - SOW - AP Format.docx.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Proposal & Contracts/AssuredPartners - Fog Solutions - Broker in a Box - SOW.docx\n",
      "Loaded ./my-docs/Broker In A Box/Proposal & Contracts/Archive/OUTDATED FORMAT Broker in a Box - AssuredPartners - Fog Solutions - CR2.docx\n",
      "Loaded ./my-docs/Broker In A Box/Proposal & Contracts/Archive/OUTDATED FORMAT Broker in a Box - AssuredPartners - Fog Solutions - CR1 with Admin.docx\n",
      "Loaded ./my-docs/Broker In A Box/Proposal & Contracts/Archive/OUTDATED FORMAT Broker in a Box - AssuredPartners - Fog Solutions - CR1.docx\n",
      "Loaded ./my-docs/Broker In A Box/Proposal & Contracts/Archive/[Not in effect, see AP formatted CR] Broker in a Box - AssuredPartners - Fog Solutions - CR1.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Proposal & Contracts/ECIF POE/POE_End_Customer_3060310_Fog Solutions Inc._CAS-1477383-D1Q5K3_573072723 - signed.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Proposal & Contracts/ECIF POE/POE_End_Customer_3060310_Fog Solutions Inc._CAS-1477383-D1Q5K3_-309549041 - signed.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Proposal & Contracts/ECIF POE/POE_End_Customer_3060310_Fog Solutions Inc._CAS-1477383-D1Q5K3_962821672 - signed.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Delivery/AP Standing Team - Burnout Chart and Data.xlsx\n",
      "Loaded ./my-docs/Broker In A Box/Delivery/ESTIMATION_PROJ TRACKER - AP - BiaB Standing Team CR2.xlsx\n",
      "Loaded ./my-docs/Broker In A Box/Delivery/Technology Overview and Infrastructure Summary.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Delivery/Technology Overview and Infrastructure Summary.docx\n",
      "Loaded ./my-docs/Broker In A Box/Delivery/Broker In a Box - Comprehensive Backlog of Work Items and Features - 10152024.xlsx\n",
      "Error loading ./my-docs/Broker In A Box/Delivery/Getting Started/Broker in a Box - Getting Started Guide - 11262924.pptx: Package not found at './my-docs/Broker In A Box/Delivery/Getting Started/Broker in a Box - Getting Started Guide - 11262924.pptx'\n",
      "Loaded ./my-docs/Broker In A Box/Delivery/Getting Started/Broker in a Box - Exec Overview (01-09-2025).pptx\n",
      "Loaded ./my-docs/Broker In A Box/Delivery/Support Materials/Broker in a Box Charter.pptx\n",
      "Loaded ./my-docs/Broker In A Box/Delivery/Support Materials/Broker in a Box Transcript - Call with Rob - July 29.docx\n",
      "Loaded ./my-docs/Broker In A Box/Delivery/Designs/BAIB - Device Collage.png\n",
      "Loaded ./my-docs/Broker In A Box/Delivery/Designs/BAIB - AI Policy Suggestions.png\n",
      "Loaded ./my-docs/Broker In A Box/Delivery/Designs/BAIB - Login.png\n",
      "Loaded ./my-docs/Broker In A Box/Delivery/Designs/BAIB - Create a Project Dialog.png\n",
      "Loaded ./my-docs/Broker In A Box/Delivery/Project Kickoff/Fog Solutions - Assured Partners - Broker in a Box - Kickoff.pptx\n",
      "Loaded ./my-docs/Broker In A Box/Delivery/AP - Production Release Required Materials/SOP-- template to be replicated.docx\n",
      "Loaded ./my-docs/Broker In A Box/Delivery/AP - Production Release Required Materials/RPA_LIFTOFF_PaperCheckDeposit_DBRecon_SDD_V1.0.docx\n",
      "Loaded ./my-docs/Broker In A Box/Delivery/AP - Production Release Required Materials/Run book - Broker in a Box - FOG DRAFT - 120924.docx\n",
      "Loaded ./my-docs/Broker In A Box/Delivery/AP - Production Release Required Materials/Run Book-- template to be replicated.docx\n",
      "Loaded ./my-docs/Broker In A Box/Delivery/AP - Production Release Required Materials/SOP - Broker in a Box - FOG DRAFT - 120924.docx\n",
      "Loaded ./my-docs/Broker In A Box/Delivery/AP - Production Release Required Materials/Release (Paper Check Deposit Bot) - Deployment Plan.xlsx\n",
      "Loaded ./my-docs/Broker In A Box/Delivery/Status updates/Assured Partners - Broker in a Box Sprint 3 Mid-Sprint- 1003241.pptx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinbooth/fog/gpt-researcher/.venv/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ./my-docs/Broker In A Box/Delivery/Status updates/Assured Partners - Broker in a Box Sprint 10 Mid-Sprint - 022125.pptx\n",
      "Loaded ./my-docs/Broker In A Box/Delivery/Status updates/Assured Partners - Broker in a Box Sprint 6b Sprint-End  -122024.pptx\n",
      "Loaded ./my-docs/Broker In A Box/Delivery/Status updates/Assured Partners - Broker in a Box Sprint 4 Sprint-End & Monthly Stakeholder Review -102524.pptx\n",
      "Loaded ./my-docs/Broker In A Box/Delivery/Status updates/Assured Partners - Broker in a Box Sprint 2 End-Sprint & Monthly Stakeholder Review - 0927241.pptx\n",
      "Loaded ./my-docs/Broker In A Box/Delivery/Status updates/Assured Partners - Broker in a Box - Mid Project AP Exec Demo - 102224.pptx\n",
      "Loaded ./my-docs/Broker In A Box/Delivery/Status updates/Assured Partners - Broker in a Box Sprint 1 Sprint-End Review - 0912241.pptx\n",
      "Loaded ./my-docs/Broker In A Box/Delivery/Status updates/Assured Partners - Broker in a Box Sprint 8 Mid-Sprint-012425.pptx\n",
      "Loaded ./my-docs/Broker In A Box/Delivery/Status updates/Assured Partners - Broker in a Box Sprint 6b Mid-Sprint  -121324.pptx\n",
      "Loaded ./my-docs/Broker In A Box/Delivery/Status updates/Assured Partners - Broker in a Box Sprint 3 End-Sprint- 101124.pptx\n",
      "Loaded ./my-docs/Broker In A Box/Delivery/Status updates/Assured Partners - Broker in a Box Sprint 7 mid-Sprint -011025.pptx\n",
      "Loaded ./my-docs/Broker In A Box/Delivery/Status updates/Assured Partners - Broker in a Box Sprint 5 Mid-Sprint -110124.pptx\n",
      "Loaded ./my-docs/Broker In A Box/Delivery/Status updates/Assured Partners - Broker in a Box Sprint 8 Sprint-End - 013125.pptx\n",
      "Loaded ./my-docs/Broker In A Box/Delivery/Status updates/Assured Partners - Broker in a Box Sprint 6a Sprint-End  -120624.pptx\n",
      "Loaded ./my-docs/Broker In A Box/Delivery/Status updates/Assured Partners - Broker in a Box Sprint 2 Mid-Sprint Review - 0920241.pptx\n",
      "Loaded ./my-docs/Broker In A Box/Delivery/Status updates/Assured Partners - Broker in a Box Sprint 6 Mid-Sprint -111524.pptx\n",
      "Loaded ./my-docs/Broker In A Box/Delivery/Status updates/Assured Partners - Broker in a Box Sprint 4 Mid-Sprint- 1018241.pptx\n",
      "Loaded ./my-docs/Broker In A Box/Delivery/Status updates/Assured Partners - Broker in a Box Sprint 5 End-Sprint -110824.pptx\n",
      "Loaded ./my-docs/Broker In A Box/Delivery/Status updates/Assured Partners - Broker in a Box Sprint 9 Mid-Sprint - 020725.pptx\n",
      "Loaded ./my-docs/Broker In A Box/Delivery/Status updates/Assured Partners - Broker in a Box Sprint 7 Sprint-End -011725.pptx\n",
      "Loaded ./my-docs/Broker In A Box/Delivery/Status updates/Assured Partners - Broker in a Box Sprint 9 Sprint-End - 021425.pptx\n",
      "Loaded ./my-docs/Broker In A Box/Delivery/Status updates/Assured Partners - Broker in a Box Sprint 6 Sprint-End & Monthly Stakeholder Review -112224.pptx\n",
      "Loaded ./my-docs/Broker In A Box/Delivery/Vision Deck/Fog AP - Vision Deck - Broker in a Box - 1024.pptx\n",
      "Loaded ./my-docs/Broker In A Box/Delivery/Vision Deck/AP-AI Roadmap & Broker in a Box review - DRAFT - 010925.pptx\n",
      "Loaded ./my-docs/Broker In A Box/Delivery/Vision Deck/Fog AP - Vision Deck - Broker in a Box.pptx\n",
      "Loaded ./my-docs/Broker In A Box/Delivery/QA & UAT/UAT Suggestion & Rules Issues List - 120424.xlsx\n",
      "Loaded ./my-docs/Broker In A Box/AP Accounts and Set-up Instructions/Setting up Okta Multi Factor credential.pdf\n",
      "Loaded ./my-docs/Broker In A Box/AP Accounts and Set-up Instructions/Assured Partners - Broker in a Box - Endorsements - Proposed Solution Overview - 01292025.pptx\n",
      "Loaded ./my-docs/Broker In A Box/AP Accounts and Set-up Instructions/RITM0137625.xlsx\n",
      "Loaded ./my-docs/Broker In A Box/ARB Review/ARB Meeting Scheduling and Required Information.docx\n",
      "Loaded ./my-docs/Broker In A Box/ARB Review/PolicyPAL Requirements.pptx\n",
      "Loaded ./my-docs/Broker In A Box/ARB Review/Assured Partners current ARB Questionnaire_PolicyPal.xlsx\n",
      "Loaded ./my-docs/Broker In A Box/ARB Review/Assured Partners ARB Questionnaire.xlsx\n",
      "Loaded ./my-docs/Broker In A Box/ARB Review/ARB Template.pptx\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/VE740 SDK URLs.txt\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Policy Checking Doc.docx\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Synergy-Arch Amendatory with current agreements.xlsx\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/ARCH CORPORATE CANOPY 2.0 FULL POLICY WITH DECLARATIONS DRAFT CLEAN.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Private Company Protection Plus Form36-9251-2.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/API for EPIC Call to ImageRight for EB Docs.docx\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/AMS Mapping from Tiana Soury, AP IT Director.xlsx\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Endorsement/TRAV ENDT-Marked Up.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Endorsement/AO endt 1-Marked Up.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Endorsement/CNA ENDT 1-Marked Up.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Endorsement/HAR ENDT 2-Marked Up.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Endorsement/SEL ENDT 3-Marked Up.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Endorsement/hanover endt 9 (2).pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Endorsement/LMI ENDT 2-Marked Up.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Policies Supplied by Rob (with Endorsements)/Hawthorn Arch.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Policies Supplied by Rob (with Endorsements)/TPG Management ERisk.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Policies Supplied by Rob (with Endorsements)/Washington Township DO EPL.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Policies Supplied by Rob (with Endorsements)/Creedence Energy DO EPL.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Policies Supplied by Rob (with Endorsements)/Noble Artificial DO EPL.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Policies Supplied by Rob (with Endorsements)/Goldenrod Capital Axis FI.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Policies Supplied by Rob (with Endorsements)/Heliart DO EPL.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Policies Supplied by Rob (with Endorsements)/Sunrise Floors DO EPL.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Policies Supplied by Rob (with Endorsements)/JET_AMG_SERVICES_LLC__SPECIMEN_ENDORSEMENTS.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/CHUBB 1_INM.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Test Policy - 8 - WESTERN_WIRE_WORKS_INC_107351202_POLICY (1).pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Test Policy3-Shining Star Childrens Advocacy Center Policy.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Chubb Property (1).pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Test Policy - 6 - FINAL Policy.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/CNA_1_Liability.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/LMI_20_Property.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Test Policy - 9 - 3535440_FinalBAMPolicy_5334215373968.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/LMI_19_Liability.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Test-Policy4.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Test Policy - 5 - Edgewood Opco, LLC EPL Primary Policy 2024-2025.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Test-Policy2.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Test Policy - 7- 01-B-ML-P80000290-01 - Aspen Skilled Healthcare, Inc. - POLICY.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Test-Policy1.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/westfield_12_Marine.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/06 09 22-23 1PKG REN AUTO OWNERS - 35819738_Liability.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/CNA_5_Property.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/westfield_13_Property.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/CHUBB 6_UMB.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/21-22 Renewal Package Policy - Auto   43557401-21_Property.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/westfield_16_Auto.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/22.23 PKG RWL -Westfield - CWP0261649_Liability.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Test Policy - 10 - T40048431.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Autoowner/AutoOwner_CRM_1.csv\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Autoowner/06 09 22-23 1PKG REN AUTO OWNERS - 35819738_Liability.csv\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Autoowner/21-22 Renewal Package Policy - Auto   43557401-21_Property.csv\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Autoowner/AutoOwner_AUT_1.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Autoowner/06 09 22-23 1PKG REN AUTO OWNERS - 35819738_Liability.json\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Autoowner/Autoowner.txt\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Autoowner/AutoOwner_CRM_1.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Autoowner/06 09 22-23 1PKG REN AUTO OWNERS - 35819738_Liability.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Autoowner/21-22 Renewal Package Policy - Auto   43557401-21_Property.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Autoowner/AutoOwner_UMB_1.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/CNA/CNA_1_Property.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/CNA/CNA 1_UMB.csv\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/CNA/CNA 1_CRM.csv\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/CNA/CNA.txt\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/CNA/CNA_1_Liability.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/CNA/CNA 1_BAUT.csv\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/CNA/CNA_1_Liability.csv\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/CNA/CNA_1_Property.csv\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/CNA/CNA 1_UMB.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/CNA/CNA 1_CRM.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Selective/Selective_AUT_1.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Selective/Selective_FLT_1.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Selective/Selective_UMB_1.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Selective/Selective_CRM_1.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Westfield/westfield_5_Property.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Westfield/westfield_12_Marine.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Westfield/westfield_16_Auto.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Westfield/22.23 PKG RWL -Westfield - CWP0261649_Liability.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Chubb/CHUBB 1_BAUT.csv\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Chubb/CHUBB 2_UMB.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Chubb/CHUBB 1_INM.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Chubb/Chubb.txt\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Chubb/CHUBB 1_CRM.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Chubb/Chubb Property (1).pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Chubb/CHUBB.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Chubb/CHUBB 1_CRM.csv\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Chubb/Chubb Property (1).csv\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Chubb/CHUBB.csv\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Chubb/CHUBB 1_BAUT.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Chubb/CHUBB 2_UMB.csv\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Chubb/CHUBB 1_INM.csv\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Liberty Mutual Insurance/LMI_19_Liability.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Liberty Mutual Insurance/LMI 1_UMB.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Liberty Mutual Insurance/LMI 1_CRM.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Liberty Mutual Insurance/LMI_19_Property.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Hanover/HANOVER 1_GL.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Hanover/HANOVER 1_CP.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Hanover/1 1 22-23 1PKG REN  Hanover  - ZH6D753555.csv\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Hanover/1 1 22-23 1PKG REN  Hanover  - ZH6D753555.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Hanover/HANOVER 1_INM.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Hanover/HANOVER 1_CRM.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Hanover/Hanover.txt\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Traveler/Travelers_FLT_1.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Traveler/Travelers_PRO_1.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Traveler/Travelers_CRM_1.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Workers Compensation/BBTEES, INC..pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Workers Compensation/DNB UNDERGROUND LLC.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Workers Compensation/3FOLD SYSTEMS LLC.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Workers Compensation/1395 REMOUNT LLC.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Workers Compensation/ALL IS WELL GROOMERS.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Workers Compensation/ALLEGHANY CORPORATION.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Workers Compensation/ALBERT RUSSO.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Workers Compensation/WestField1.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Workers Compensation/AUGUSTA SASH AND DOOR SALES OF GA INC.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Rules Templates and Manual Evaluation/AP - Rules Template For Selecting Core Rules - 021825.xlsx\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Rules Templates and Manual Evaluation/AP Rules Structure & Refinement Workshop - 010625.xlsx\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Rules Templates and Manual Evaluation/AP_Broker In a Box - Rules Template  - ML Updated - 01162025.xlsx\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Rules Templates and Manual Evaluation/Fog-AP - Rules Manual Evaluation-121624.xlsx\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Rules Templates and Manual Evaluation/Filled Rules Template/AP_Broker In a Box - Rules Template  - Updated - 102224.xlsx\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Rules Templates and Manual Evaluation/Filled Rules Template/ARCH CORPORATE CANOPY 2.0 FULL POLICY WITH DECLARATIONS DRAFT CLEAN.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Rules Templates and Manual Evaluation/Filled Rules Template/AP_Broker In a Box - Rules Template .xlsx\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Rules Templates and Manual Evaluation/AP - BA Team Rules Template Analysis/Travelers Employment Practices Liability - BA Team Reference.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Rules Templates and Manual Evaluation/AP - BA Team Rules Template Analysis/AP_Broker In a Box - Rules Template  - Updated - 102224 (3).xlsx\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Rules Templates and Manual Evaluation/AP - BA Team Rules Template Analysis/Chubb (Westchester)- Employment Practices Liability - BA Team reference.pdf\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Rules Templates and Manual Evaluation/AP - BA Team Rules Template Analysis/Rules Template Interpretation - AP BA Team - 111524.xlsx\n",
      "Loaded ./my-docs/Broker In A Box/Client Supplied/Rules Templates and Manual Evaluation/AP - BA Team Rules Template Analysis/ARCH CORPORATE CANOPY 2.0 FULL POLICY WITH DECLARATIONS DRAFT CLEAN - BA Team Reference.pdf\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "\n",
    "def load_document_paths(directory):\n",
    "    document_paths = []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(('.pptx', '.xlsx', '.docx', '.pdf', '.png', '.jpg', '.jpeg', '.txt', '.csv', '.json', 'yaml', '.html')):\n",
    "                document_paths.append(os.path.join(root, file))\n",
    "    return document_paths\n",
    "\n",
    "document_paths = load_document_paths('./my-docs')\n",
    "all_documents = []\n",
    "for document_path in document_paths:\n",
    "    loader = UnstructuredFileLoader(document_path)\n",
    "    try:\n",
    "        document = loader.load()\n",
    "        print(f\"Loaded {document_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {document_path}: {e}\")\n",
    "        continue\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "    documents = text_splitter.split_documents(document)\n",
    "    all_documents.extend(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load/save documents to store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import faiss\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "\n",
    "document_embeddings = embeddings.embed_documents([doc.page_content for doc in all_documents])\n",
    "\n",
    "# Initialize the FAISS index\n",
    "dimension = len(document_embeddings[0])\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "doc_store = InMemoryDocstore()\n",
    "# Create the FAISS vector store\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings, \n",
    "    index=index, \n",
    "    docstore=doc_store, \n",
    "    index_to_docstore_id={})\n",
    "\n",
    "\n",
    "\n",
    "# Add documents and their embeddings to the vector store\n",
    "vector_store.add_documents(all_documents)\n",
    "# Save the FAISS index and documents\n",
    "vector_store.save_local(\"faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = FAISS.load_local(\"faiss_index\", embeddings, allow_dangerous_deserialization=True)\n",
    "chroma = Chroma(embedding_function=embeddings, persist_directory=\".chroma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     [12:16:04] 🔍 Starting the research task for '\n",
      "You are to create a design document that describes, in detail, a solutions design for Assured Partners Broker in a box.\n",
      "\n",
      "Use the sections provided to create a detailed report.  Each section should be expanded to include as much detail as possible.  Use the internet to expand on recommended practices.\n",
      "\n",
      "Be verbose and expand and topics as much as possible.  If the vecttor_store provided doesn't have informmation, state would should be in each sub topic provided.\n",
      "\n",
      "Do not mention anything about Amynta, but assume the Broker in the box data fabric implmentation is similar.\n",
      "\n",
      "Use the internet to expand on recommended practices.\n",
      "\n",
      "The report sections should be as follows:\n",
      "\n",
      "\"Project Summary\", \"Scope of the Solution\", \"Stakeholders and Audiences\", \"Solution Design Overview\", \"User Roles and Security Considerations\", \"Definition of User Roles\", \"Data Sources and Ingestion\", \"Data Ingestion Strategy\", \"Data Storage and Management\", \"Storage Solutions\", \"Data Retention and Archival Policies\", \"Data Encryption and Data Security\", \"Encryption Methods\", \"Data Security Techniques\", \"Analytics and Reporting\", \"Reporting\", \"Analytics Services\", \"DevOps Integration\", \"Source Control Management\", \"Code Deployment and Management Processes\", \"Rollback Strategies\", \"Cloud Fundamentals/Readiness\", \"Regional Planning and Data Center Utilization\", \"Network and Infrastructure Setup\", \"Azure Resources\", \"Network\", \"Identity and Access Management\", \"Cost Optimization and Governance\", \"Backup and Recovery Solutions\", \"High Availability/Disaster Recovery Plan\", \"Monitoring and Alert Systems\", \"Appendix and References\", \"Glossary of Terms\", \"Reference Documents\"\n",
      "\n",
      "\n",
      "'...\n",
      "INFO:     [12:16:04] 🖥️ IT Solutions Architect Agent\n",
      "INFO:     [12:16:04] 🌐 Browsing the web to learn more about the task: \n",
      "You are to create a design document that describes, in detail, a solutions design for Assured Partners Broker in a box.\n",
      "\n",
      "Use the sections provided to create a detailed report.  Each section should be expanded to include as much detail as possible.  Use the internet to expand on recommended practices.\n",
      "\n",
      "Be verbose and expand and topics as much as possible.  If the vecttor_store provided doesn't have informmation, state would should be in each sub topic provided.\n",
      "\n",
      "Do not mention anything about Amynta, but assume the Broker in the box data fabric implmentation is similar.\n",
      "\n",
      "Use the internet to expand on recommended practices.\n",
      "\n",
      "The report sections should be as follows:\n",
      "\n",
      "\"Project Summary\", \"Scope of the Solution\", \"Stakeholders and Audiences\", \"Solution Design Overview\", \"User Roles and Security Considerations\", \"Definition of User Roles\", \"Data Sources and Ingestion\", \"Data Ingestion Strategy\", \"Data Storage and Management\", \"Storage Solutions\", \"Data Retention and Archival Policies\", \"Data Encryption and Data Security\", \"Encryption Methods\", \"Data Security Techniques\", \"Analytics and Reporting\", \"Reporting\", \"Analytics Services\", \"DevOps Integration\", \"Source Control Management\", \"Code Deployment and Management Processes\", \"Rollback Strategies\", \"Cloud Fundamentals/Readiness\", \"Regional Planning and Data Center Utilization\", \"Network and Infrastructure Setup\", \"Azure Resources\", \"Network\", \"Identity and Access Management\", \"Cost Optimization and Governance\", \"Backup and Recovery Solutions\", \"High Availability/Disaster Recovery Plan\", \"Monitoring and Alert Systems\", \"Appendix and References\", \"Glossary of Terms\", \"Reference Documents\"\n",
      "\n",
      "\n",
      "...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tavily API key not found, set to blank. If you need a retriver, please set the TAVILY_API_KEY environment variable.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     [12:16:04] 🤔 Planning the research strategy and subtasks...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 400 Client Error: Bad Request for url: https://api.tavily.com/search. Failed fetching sources. Resulting in empty response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     [12:16:05] 🗂️  I will conduct my research based on the following queries: ['best practices for creating a solutions design document for data fabric architecture', 'data ingestion strategies and tools for cloud-based solutions 2025', 'modern encryption methods and data security techniques for cloud systems', 'DevOps integration and rollback strategies for Azure-based deployments', '\\nYou are to create a design document that describes, in detail, a solutions design for Assured Partners Broker in a box.\\n\\nUse the sections provided to create a detailed report.  Each section should be expanded to include as much detail as possible.  Use the internet to expand on recommended practices.\\n\\nBe verbose and expand and topics as much as possible.  If the vecttor_store provided doesn\\'t have informmation, state would should be in each sub topic provided.\\n\\nDo not mention anything about Amynta, but assume the Broker in the box data fabric implmentation is similar.\\n\\nUse the internet to expand on recommended practices.\\n\\nThe report sections should be as follows:\\n\\n\"Project Summary\", \"Scope of the Solution\", \"Stakeholders and Audiences\", \"Solution Design Overview\", \"User Roles and Security Considerations\", \"Definition of User Roles\", \"Data Sources and Ingestion\", \"Data Ingestion Strategy\", \"Data Storage and Management\", \"Storage Solutions\", \"Data Retention and Archival Policies\", \"Data Encryption and Data Security\", \"Encryption Methods\", \"Data Security Techniques\", \"Analytics and Reporting\", \"Reporting\", \"Analytics Services\", \"DevOps Integration\", \"Source Control Management\", \"Code Deployment and Management Processes\", \"Rollback Strategies\", \"Cloud Fundamentals/Readiness\", \"Regional Planning and Data Center Utilization\", \"Network and Infrastructure Setup\", \"Azure Resources\", \"Network\", \"Identity and Access Management\", \"Cost Optimization and Governance\", \"Backup and Recovery Solutions\", \"High Availability/Disaster Recovery Plan\", \"Monitoring and Alert Systems\", \"Appendix and References\", \"Glossary of Terms\", \"Reference Documents\"\\n\\n\\n']...\n",
      "INFO:     [12:16:05] \n",
      "🔍 Running research for 'best practices for creating a solutions design document for data fabric architecture'...\n",
      "INFO:     [12:16:05]  Getting relevant content based on query: best practices for creating a solutions design document for data fabric architecture...\n",
      "INFO:     [12:16:05] \n",
      "🔍 Running research for 'data ingestion strategies and tools for cloud-based solutions 2025'...\n",
      "INFO:     [12:16:05]  Getting relevant content based on query: data ingestion strategies and tools for cloud-based solutions 2025...\n",
      "INFO:     [12:16:05] \n",
      "🔍 Running research for 'modern encryption methods and data security techniques for cloud systems'...\n",
      "INFO:     [12:16:05]  Getting relevant content based on query: modern encryption methods and data security techniques for cloud systems...\n",
      "INFO:     [12:16:05] \n",
      "🔍 Running research for 'DevOps integration and rollback strategies for Azure-based deployments'...\n",
      "INFO:     [12:16:05]  Getting relevant content based on query: DevOps integration and rollback strategies for Azure-based deployments...\n",
      "INFO:     [12:16:05] \n",
      "🔍 Running research for '\n",
      "You are to create a design document that describes, in detail, a solutions design for Assured Partners Broker in a box.\n",
      "\n",
      "Use the sections provided to create a detailed report.  Each section should be expanded to include as much detail as possible.  Use the internet to expand on recommended practices.\n",
      "\n",
      "Be verbose and expand and topics as much as possible.  If the vecttor_store provided doesn't have informmation, state would should be in each sub topic provided.\n",
      "\n",
      "Do not mention anything about Amynta, but assume the Broker in the box data fabric implmentation is similar.\n",
      "\n",
      "Use the internet to expand on recommended practices.\n",
      "\n",
      "The report sections should be as follows:\n",
      "\n",
      "\"Project Summary\", \"Scope of the Solution\", \"Stakeholders and Audiences\", \"Solution Design Overview\", \"User Roles and Security Considerations\", \"Definition of User Roles\", \"Data Sources and Ingestion\", \"Data Ingestion Strategy\", \"Data Storage and Management\", \"Storage Solutions\", \"Data Retention and Archival Policies\", \"Data Encryption and Data Security\", \"Encryption Methods\", \"Data Security Techniques\", \"Analytics and Reporting\", \"Reporting\", \"Analytics Services\", \"DevOps Integration\", \"Source Control Management\", \"Code Deployment and Management Processes\", \"Rollback Strategies\", \"Cloud Fundamentals/Readiness\", \"Regional Planning and Data Center Utilization\", \"Network and Infrastructure Setup\", \"Azure Resources\", \"Network\", \"Identity and Access Management\", \"Cost Optimization and Governance\", \"Backup and Recovery Solutions\", \"High Availability/Disaster Recovery Plan\", \"Monitoring and Alert Systems\", \"Appendix and References\", \"Glossary of Terms\", \"Reference Documents\"\n",
      "\n",
      "\n",
      "'...\n",
      "INFO:     [12:16:05]  Getting relevant content based on query: \n",
      "You are to create a design document that describes, in detail, a solutions design for Assured Partners Broker in a box.\n",
      "\n",
      "Use the sections provided to create a detailed report.  Each section should be expanded to include as much detail as possible.  Use the internet to expand on recommended practices.\n",
      "\n",
      "Be verbose and expand and topics as much as possible.  If the vecttor_store provided doesn't have informmation, state would should be in each sub topic provided.\n",
      "\n",
      "Do not mention anything about Amynta, but assume the Broker in the box data fabric implmentation is similar.\n",
      "\n",
      "Use the internet to expand on recommended practices.\n",
      "\n",
      "The report sections should be as follows:\n",
      "\n",
      "\"Project Summary\", \"Scope of the Solution\", \"Stakeholders and Audiences\", \"Solution Design Overview\", \"User Roles and Security Considerations\", \"Definition of User Roles\", \"Data Sources and Ingestion\", \"Data Ingestion Strategy\", \"Data Storage and Management\", \"Storage Solutions\", \"Data Retention and Archival Policies\", \"Data Encryption and Data Security\", \"Encryption Methods\", \"Data Security Techniques\", \"Analytics and Reporting\", \"Reporting\", \"Analytics Services\", \"DevOps Integration\", \"Source Control Management\", \"Code Deployment and Management Processes\", \"Rollback Strategies\", \"Cloud Fundamentals/Readiness\", \"Regional Planning and Data Center Utilization\", \"Network and Infrastructure Setup\", \"Azure Resources\", \"Network\", \"Identity and Access Management\", \"Cost Optimization and Governance\", \"Backup and Recovery Solutions\", \"High Availability/Disaster Recovery Plan\", \"Monitoring and Alert Systems\", \"Appendix and References\", \"Glossary of Terms\", \"Reference Documents\"\n",
      "\n",
      "\n",
      "...\n",
      "INFO:     [12:16:05] 📃 Source: ./my-docs/Broker In A Box/Delivery/AP - Production Release Required Materials/RPA_LIFTOFF_PaperCheckDeposit_DBRecon_SDD_V1.0.docx\n",
      "Title: None\n",
      "Content: VERSION DESCRIPTION REVIEWED BY APPROVED BY DATE 1.0 Initial SDD Jithin George Jithin George\n",
      "\n",
      "\n",
      "\n",
      "Purpose\t\n",
      "\n",
      "The Solution Design Document (SDD) is created for every business process that is automated using the RPA technology. The SDD document needs to be reviewed and updated for every change requested and applied to the automation process. This document will provide a technical snapshot and must and should always reflect the latest design and key features of the automated workflow.\n",
      "\n",
      "The document naming convention will follow the naming convention and the version of the automated process. This can be “business process name version” or it can be defined, case by case, as part of the larger RPA project design.\n",
      "\n",
      "Source: ./my-docs/Broker In A Box/Delivery/Status updates/Assured Partners - Broker in a Box - Mid Project AP Exec Demo - 102224.pptx\n",
      "Title: None\n",
      "Content: Enterprise Fabric Platform build out featuring Cotiviti use case\n",
      "\n",
      "Enterprise Data Platform\n",
      "\n",
      "Agenda\n",
      "\n",
      "1\n",
      "\n",
      "2\n",
      "\n",
      "3\n",
      "\n",
      "Source: ./my-docs/Broker In A Box/Proposal & Contracts/ECIF PO 101108580 AssuredPartners.pdf\n",
      "Title: None\n",
      "Content: use case. 0 Architecture Review — Review existing infrastructure and determine what components are reusable and what needs to be added. Expected workloads include: AOAI, Al Search, Cosmos, Doc Intelligence, APIM, AKS, Logic Apps, and Fabric. o Identify data sources land develop technical architecture. o Connect into AssuredPartners existing GitHub repository land setup development environments including Visual Studio and GitHub Copilot. Development languages will include Angular for the front end, C# for the services tier, Python for the d\n",
      "\n",
      "09/30/2024\n",
      "\n",
      "Source: ./my-docs/Broker In A Box/Proposal & Contracts/AssuredPartners - Fog Solutions - Broker in a Box - Exhibit A.docx\n",
      "Title: None\n",
      "Content: An architecture session will be held with the other Fabric team (Jeff Hathaway, Scott Mayer, Mohammad Karim) to develop a broader Fabric roadmap, but this proposal does not include any implementation of Fabric beyond what’s needed for the Broker in a Box solution. \n",
      "\n",
      "Fog Solutions reserves the right to reference the work performed for clients in the context of our portfolio of projects. This does not constitute a reference or formal case study, which may be requested and would require written client approval.\n",
      "\n",
      "Price includes:\n",
      "\n",
      "Fog Solutions laptop issued to consultants, loaded with properly licensed productivity software.\n",
      "\n",
      "Extended Fog Solutions team providing technical support for project consultants, as needed, to complete the deliverables described in this proposal.\n",
      "\n",
      "Price excludes:\n",
      "\n",
      "Cloud (i.e., Azure), database, third party product and application server licenses.\n",
      "\n",
      "Limited travel that will be pre-approved by client. \n",
      "\n",
      "Commercial Plan\n",
      "\n",
      "Deliverables and Work Schedule\n",
      "\n",
      "Source: ./my-docs/Broker In A Box/Delivery/Status updates/Assured Partners - Broker in a Box Sprint 3 Mid-Sprint- 1003241.pptx\n",
      "Title: None\n",
      "Content: Configure environment for Fabric initial use case                                         Oct. 7th, 2024    On track\n",
      "Complete the business rules template [AP Business Team]                                   Oct. 9th, 2024    With RobR to fill out\n",
      "Complete research for prompt architecture development                                     Oct. 11th, 2024   Business rules template dependency\n",
      "Complete research MS AD & Okta integration                                                Oct. 11th, 2024   On track\n",
      "Prepare for deployment and configuration of dev scripts for deployment in AP Azure Cloud  Oct. 11th, 2024   On track\n",
      "Support for multiple user roles (architecture)                                            Oct 11th, 2024    On track\n",
      "Set-up and configure development environment and services                                 Sept. 27th, 2024  ARB Approval Dependency\n",
      "\n",
      "Source: ./my-docs/Broker In A Box/Proposal & Contracts/AssuredPartners - Fog Solutions - Broker in a Box - AP Formated SOW - Fully Executed.pdf\n",
      "Title: None\n",
      "Content: An architecture session will be held with the other Fabric team (Jeff Hathaway, Scott Mayer, Mohammad Karim) to develop a broader Fabric roadmap, but this proposal does not include any implementation of Fabric beyond what’s needed for the Broker in a Box solution.\n",
      "\n",
      "\n",
      "\n",
      "Fog Solutions reserves the right to reference the work performed for clients in the context of our portfolio of projects. This does not constitute a reference or formal case study, which may be requested and would require written client approval.\n",
      "\n",
      "Price includes:\n",
      "\n",
      "\n",
      "\n",
      "Fog Solutions laptop issued to consultants, loaded with properly licensed productivity software.\n",
      "\n",
      "\n",
      "\n",
      "Extended Fog Solutions team providing technical support for project consultants, as needed, to complete the deliverables described in this proposal.\n",
      "\n",
      "Price excludes:\n",
      "\n",
      "Cloud (i.e., Azure), database, third party product and application server licenses.\n",
      "\n",
      "\n",
      "\n",
      "Limited travel that will be pre-approved by client.\n",
      "\n",
      "4. Commercial Plan\n",
      "\n",
      "Source: ./my-docs/Broker In A Box/Proposal & Contracts/AssuredPartners - Fog Solutions - Broker in a Box - SOW.docx\n",
      "Title: None\n",
      "Content: The solution will include the deployment of APIM and will use Fabric on the back end to build a scalable and production ready application for AssuredPartners.  \n",
      "\n",
      "An architecture session will be held with the other Fabric team (Jeff Hathaway, Scott Mayer, Mohammad Karim) to develop a broader Fabric roadmap, but this proposal does not include any implementation of Fabric beyond what’s needed for the Broker in a Box solution. \n",
      "\n",
      "Fog Solutions reserves the right to reference the work performed for clients in the context of our portfolio of projects. This does not constitute a reference or formal case study, which may be requested and would require written client approval.\n",
      "\n",
      "Price includes:\n",
      "\n",
      "Fog Solutions laptop issued to consultants, loaded with properly licensed productivity software.\n",
      "\n",
      "Extended Fog Solutions team providing technical support for project consultants, as needed, to complete the deliverables described in this proposal.\n",
      "\n",
      "Price excludes:\n",
      "\n",
      "Source: ./my-docs/Broker In A Box/Proposal & Contracts/AssuredPartners - Fog Solutions - Broker in a Box - SOW.docx\n",
      "Title: None\n",
      "Content: Sprint 1 – Kickoff and Solution Design\n",
      "\n",
      "Project Kickoff – Align on project goals, timelines, assumptions, communications, and teaming plan across Client and Fog to create one integrated, high functioning team.\n",
      "\n",
      "Use Case workshops – Conduct requirements workshops with key business and IT stakeholders to refine the initial broker in a box use case.\n",
      "\n",
      "Architecture Discovery – Review existing infrastructure and determine what components are reusable and what needs to be added.\n",
      "\n",
      "Identify data sources and develop technical architecture.\n",
      "\n",
      "Sprint 2 – User Experience and Technical Foundation \n",
      "\n",
      "Create wireframes and visuals for user experience.\n",
      "\n",
      "Begin developing prompt architecture.\n",
      "\n",
      "Work with AssuredPartners to configure any necessary changes to dev environment.\n",
      "\n",
      "Hold a broader architectural workshop on the Fabric roadmap and usage for the Broker in a Box solution.\n",
      "\n",
      "Deploy core architecture components to dev environment.\n",
      "\n",
      "Sprints 3 through 5 – Iterative Application Build\n",
      "\n",
      "INFO:     [12:16:05] 📃 Source: ./my-docs/Broker In A Box/Delivery/AP - Production Release Required Materials/SOP-- template to be replicated.docx\n",
      "Title: None\n",
      "Content: Assured Partners\n",
      "\n",
      "Assured Partners\n",
      "\n",
      "SOP: (Name of the project)\n",
      "\n",
      "Document Revision History\n",
      "\n",
      "Version Date ( mm-dd-yyyy) Sections Changed By Comments 1\n",
      "\n",
      "\n",
      "\n",
      "Table of Contents\n",
      "\n",
      "1\tIntroduction\t4\n",
      "\n",
      "1.1\tPurpose\t4\n",
      "\n",
      "1.2\tAudience\t4\n",
      "\n",
      "1.3\tOverview\t4\n",
      "\n",
      "1.4\tAssumptions\t4\n",
      "\n",
      "1.5\tChange Control\t4\n",
      "\n",
      "1.6\tAdditional Notes & Tips\t5\n",
      "\n",
      "1.7\tAudit\t5\n",
      "\n",
      "1.8\tCommunication\t5\n",
      "\n",
      "1.9\tReference Documents\t5\n",
      "\n",
      "2\tDesign\t6\n",
      "\n",
      "2.1\tData mapping\t6\n",
      "\n",
      "2.2\tData Model\t6\n",
      "\n",
      "3\tExecution\t7\n",
      "\n",
      "3.1\tExecution diagram\t7\n",
      "\n",
      "3.2\tExecution (Tools Used)\t8\n",
      "\n",
      "3.3\tExecution Steps (ETL Components)\t8\n",
      "\n",
      "3.4\tExecution Steps (Database Components)\t8\n",
      "\n",
      "3.5\tAuthentication & Authorization\t8\n",
      "\n",
      "4\tRollback(Failed)\t17\n",
      "\n",
      "5\tIT Contact details\t18\n",
      "\n",
      "\n",
      "\n",
      "Introduction\n",
      "\n",
      "Purpose\n",
      "\n",
      "(Write the purpose of the project+ this document)\n",
      "\n",
      "Audience  (Mention the intended audience for whom this document was prepared )\n",
      "\n",
      "Overview - \n",
      "\n",
      "Assumptions - \n",
      "\n",
      "Change Control – \n",
      "\n",
      "Additional Notes & Tips – \n",
      "\n",
      "Audit - Data Audit (NA)\n",
      "\n",
      "Communication – \n",
      "\n",
      "Your Team Team:\n",
      "\n",
      "S# Name Location Customer email id 1 2 3\n",
      "\n",
      "Source: ./my-docs/Broker In A Box/ARB Review/ARB Template.pptx\n",
      "Title: None\n",
      "Content: Broker in a Box – Support for Endorsements and Admin Page Architecture Review\n",
      "\n",
      "Agenda\n",
      "\n",
      "Business Requirement\n",
      "\n",
      "(High Level - Brief Narrative)\n",
      "\n",
      "3\n",
      "\n",
      "Potential Risks\n",
      "\n",
      "Policy data is retrieved from an AMS and parts are stored across Blob storage, Azure SQL, and Fabric\n",
      "\n",
      "Review data storage guidelines and AP data classification policies\n",
      "\n",
      "Work with AP teams to enable Fabric to be used for the Broker-in-a-box project\n",
      "\n",
      "Policy data as well as AP business knowledge will be used with Generative AI\n",
      "\n",
      "Leverage LLMs where data is not made available to the LLM publisher\n",
      "\n",
      "Provide auditing and logging of all LLM usage, prompts, and  responses\n",
      "\n",
      "Broker-in-a-box introduces new technologies from a support and SRE perspective\n",
      "\n",
      "Provide KT \n",
      "\n",
      "Align on longer term support strategy\n",
      "\n",
      "New integration with AMS\n",
      "\n",
      "4\n",
      "\n",
      "Capabilities and Functionality\n",
      "\n",
      "Okta integration for user auth\n",
      "\n",
      "Applied Epic SOAP integration to pull policies for review\n",
      "\n",
      "PDF file upload\n",
      "\n",
      "Source: ./my-docs/Broker In A Box/Delivery/AP - Production Release Required Materials/Run book - Broker in a Box - FOG DRAFT - 120924.docx\n",
      "Title: None\n",
      "Content: Runbook for Broker in a Box Web Application\n",
      "\n",
      "1. Document Control\n",
      "\n",
      "Revision History\n",
      "\n",
      "Revision Number Revision Date Summary of Changes Made Changed By 1.0 11-06-2024 Initial version Fog Team\n",
      "\n",
      "2. Introduction\n",
      "\n",
      "This runbook serves as a comprehensive guide for managing and maintaining the Broker in a Box (BIB) web application. It is designed for use by system administrators, DevOps engineers, and support teams.\n",
      "\n",
      "2.1 Purpose\n",
      "\n",
      "This document outlines the operational procedures, protocols, and best practices to ensure the application's availability, performance, and reliability. It provides a centralized reference for:\n",
      "\n",
      "Incident management.\n",
      "\n",
      "Regular maintenance tasks.\n",
      "\n",
      "Deployment and scaling.\n",
      "\n",
      "Backup and disaster recovery.\n",
      "\n",
      "3. Scope\n",
      "\n",
      "This runbook covers the following areas:\n",
      "\n",
      "Day-to-day operations of the BIB application.\n",
      "\n",
      "Deployment and configuration management.\n",
      "\n",
      "Incident resolution and troubleshooting.\n",
      "\n",
      "Security and compliance guidelines.\n",
      "\n",
      "4. Application Overview\n",
      "\n",
      "4.1 Business Description\n",
      "\n",
      "Source: ./my-docs/Broker In A Box/Delivery/Status updates/Assured Partners - Broker in a Box Sprint 10 Mid-Sprint - 022125.pptx\n",
      "Title: None\n",
      "Content: Establish initial app design and UX direction\n",
      "\n",
      "Setup framework for the app\n",
      "\n",
      "Gather Rules data\n",
      "\n",
      "Ship \u000bBroker in a Box to pilot users!\n",
      "\n",
      "Implement additional improvements\n",
      "\n",
      "Refine rules\n",
      "\n",
      "Admin Page for self-serve rules mgmt\n",
      "\n",
      "Complete remaining integration tasks\n",
      "\n",
      "UAT and QA Test Passes\n",
      "\n",
      "Address QA issues and evaluate approach to address UAT issues\n",
      "\n",
      "Complete ARB Review\n",
      "\n",
      "Work with AP to configure any dev environment (Cloud team dependency)\n",
      "\n",
      "Implement initial UI to create a Policy Review and search against rules engine\n",
      "\n",
      "Implement and tune prompts for AI recommendations\n",
      "\n",
      "Add support for Accept/Ignore \n",
      "\n",
      "Add support for all coverages in policy type and all rules\n",
      "\n",
      "Continue to tune the prompts\n",
      "\n",
      "Complete front/back-end integration\n",
      "\n",
      "Implement UAT issue fixes\n",
      "\n",
      "Perform additional UAT pass\n",
      "\n",
      "Ship \u000bBroker in a Box to pilot users!\n",
      "\n",
      "Stick figuring it out…\n",
      "\n",
      "VIEW AND MANAGE POLICY REVIEWS\n",
      "\n",
      "Source: ./my-docs/Broker In A Box/Delivery/Status updates/Assured Partners - Broker in a Box Sprint 9 Mid-Sprint - 020725.pptx\n",
      "Title: None\n",
      "Content: Establish initial app design and UX direction\n",
      "\n",
      "Setup framework for the app\n",
      "\n",
      "Gather Rules data\n",
      "\n",
      "Ship \u000bBroker in a Box to pilot users!\n",
      "\n",
      "Implement additional improvements\n",
      "\n",
      "Refine rules\n",
      "\n",
      "Admin Page for self-serve rules mgmt\n",
      "\n",
      "Complete remaining integration tasks\n",
      "\n",
      "UAT and QA Test Passes\n",
      "\n",
      "Address QA issues and evaluate approach to address UAT issues\n",
      "\n",
      "Complete ARB Review\n",
      "\n",
      "Work with AP to configure any dev environment (Cloud team dependency)\n",
      "\n",
      "Implement initial UI to create a Policy Review and search against rules engine\n",
      "\n",
      "Implement and tune prompts for AI recommendations\n",
      "\n",
      "Add support for Accept/Ignore \n",
      "\n",
      "Add support for all coverages in policy type and all rules\n",
      "\n",
      "Continue to tune the prompts\n",
      "\n",
      "Complete front/back-end integration\n",
      "\n",
      "Implement UAT issue fixes\n",
      "\n",
      "Perform additional UAT pass\n",
      "\n",
      "Ship \u000bBroker in a Box to pilot users!\n",
      "\n",
      "Stick figuring it out…\n",
      "\n",
      "VIEW AND MANAGE POLICY REVIEWS\n",
      "\n",
      "Source: ./my-docs/Broker In A Box/Delivery/Status updates/Assured Partners - Broker in a Box Sprint 9 Sprint-End - 021425.pptx\n",
      "Title: None\n",
      "Content: Establish initial app design and UX direction\n",
      "\n",
      "Setup framework for the app\n",
      "\n",
      "Gather Rules data\n",
      "\n",
      "Ship \u000bBroker in a Box to pilot users!\n",
      "\n",
      "Implement additional improvements\n",
      "\n",
      "Refine rules\n",
      "\n",
      "Admin Page for self-serve rules mgmt\n",
      "\n",
      "Complete remaining integration tasks\n",
      "\n",
      "UAT and QA Test Passes\n",
      "\n",
      "Address QA issues and evaluate approach to address UAT issues\n",
      "\n",
      "Complete ARB Review\n",
      "\n",
      "Work with AP to configure any dev environment (Cloud team dependency)\n",
      "\n",
      "Implement initial UI to create a Policy Review and search against rules engine\n",
      "\n",
      "Implement and tune prompts for AI recommendations\n",
      "\n",
      "Add support for Accept/Ignore \n",
      "\n",
      "Add support for all coverages in policy type and all rules\n",
      "\n",
      "Continue to tune the prompts\n",
      "\n",
      "Complete front/back-end integration\n",
      "\n",
      "Implement UAT issue fixes\n",
      "\n",
      "Perform additional UAT pass\n",
      "\n",
      "Ship \u000bBroker in a Box to pilot users!\n",
      "\n",
      "Stick figuring it out…\n",
      "\n",
      "VIEW AND MANAGE POLICY REVIEWS\n",
      "\n",
      "Source: ./my-docs/Broker In A Box/Delivery/Status updates/Assured Partners - Broker in a Box Sprint 6a Sprint-End  -120624.pptx\n",
      "Title: None\n",
      "Content: Complete backend work for policy chat sessions.\n",
      "\n",
      "Deliver UI updates to: Show policy chat sessions for claims associates and allow brokers to chat and ask questions about policy documents.\n",
      "\n",
      "Start development of UI for adding and managing rules.\n",
      "\n",
      "Implement rule management backend.\n",
      "\n",
      "Stakeholder Feedback:\n",
      "\n",
      "Demo functional chat modules and Admin Panel progress.\n",
      "\n",
      "Project Kickoff -  Review vision for the project, align on high level goals and outcomes\n",
      "\n",
      "Information Architecture & Design -  establish IA and design for integration of Broker in a Box into PolicyPal\n",
      "\n",
      "Requirements -  finalize core use cases and requirements for integration and confirm final integration scope\n",
      "\n",
      "Development\n",
      "\n",
      "Finalize and deploy support for policy chat sessions and multi-document ingestion.\n",
      "\n",
      "Conduct UAT for role-based views and chat functionality and rule management functionality.\n",
      "\n",
      "Implement any final adjustments or enhancements.\n",
      "\n",
      "Integration Testing:\n",
      "\n",
      "Source: ./my-docs/Broker In A Box/Delivery/Status updates/Assured Partners - Broker in a Box Sprint 7 mid-Sprint -011025.pptx\n",
      "Title: None\n",
      "Content: Project Kickoff -  Review vision for the project, align on high level goals and outcomes\n",
      "\n",
      "Information Architecture & Design -  establish IA and design for integration of Broker in a Box into PolicyPal\n",
      "\n",
      "Requirements -  finalize core use cases and requirements for integration and confirm final integration scope\n",
      "\n",
      "Development\n",
      "\n",
      "Finalize and deploy support for policy chat sessions and multi-document ingestion.\n",
      "\n",
      "Conduct UAT for role-based views and chat functionality and rule management functionality.\n",
      "\n",
      "Implement any final adjustments or enhancements.\n",
      "\n",
      "Integration Testing:\n",
      "\n",
      "Perform end-to-end testing to ensure seamless functionality between components.\n",
      "\n",
      "Deployment:\n",
      "\n",
      "Deploy all functionalities to production in coordinated releases.\n",
      "\n",
      "Monitor initial usage and resolve issues.\n",
      "\n",
      "Stakeholder Review:\n",
      "\n",
      "Present deployed solution and gather final feedback for future improvements.\n",
      "\n",
      "On track / Complete\n",
      "\n",
      "Dec 9th  –  Dec 20th, 2024\u000bSprint 6a & 6b Activities & Status\n",
      "\n",
      "Dependency\n",
      "\n",
      "Blocked/Off track\n",
      "\n",
      "INFO:     [12:16:05] 📃 Source: ./my-docs/Amynta Group - Solution Design.docx\n",
      "Title: None\n",
      "Content: Datatype – Structured data from a SQL Server source\n",
      "\n",
      "Data Ingest Frequency – Daily\n",
      "\n",
      "Expected Volumes –\n",
      "\n",
      "Historical: < 50 GB\n",
      "\n",
      "Incremental: <200 MB\n",
      "\n",
      "Future Data Sources\n",
      "\n",
      "The following table shows the list of data sources in priority order that will be leveraged throughout the various phases of the engagement.\n",
      "\n",
      "Source Systems Average Amount of Reporting from Source WarranTech 40% Guardsman 35% TPA 35%\n",
      "\n",
      "All sources are internet accessible API extracts with an Amynta Group token, CSVs, or SQL-based sources. The token is managed by Azure Key Vault for secure access.\n",
      "\n",
      "4.2 Data Ingestion Strategy\n",
      "\n",
      "Data ingestion is performed through Fabric Data Factory for orchestration of copy data pipelines and notebooks. Each source has its own orchestration pipeline so it can run as a stand-alone process but there is also a master orchestration pipeline that runs one time per day that executes each child pipeline for each source. For the sources in this current phase:\n",
      "\n",
      "Source: ./my-docs/Amynta Group - Solution Design.docx\n",
      "Title: None\n",
      "Content: ALIS – this API call to ingest the raw data is implemented in a Spark Notebook inside of Fabric. Since the API call is a more complex source with specific vendor requirements on how to pull the data, a Notebook is used.\n",
      "\n",
      "IMS – this data is extracted over a Fabric Gateway and using Fabric Data Factory and copy activity pipelines to securely access the SQL Server data hosted on a private virtual network and Azure VM.\n",
      "\n",
      "Within each pipeline and notebook in the ingestion layer, a metadata framework is leveraged that uses pipeline variables (json) and Lakehouse control tables, in the Utility Lakehouse. There are 2 key phases of data ingestion in the medallion architecture, these are:\n",
      "\n",
      "Source: ./my-docs/Amynta Group - Solution Design.docx\n",
      "Title: None\n",
      "Content: During the pilot phase Direct-Lake with RLS was demonstrated with the IMS source to show how different types of servers can be secured with RLS roles. For the implementation phase, Amynta Group elected not to leverage RLS at this time to maximize data analysis and promote access to data.\n",
      "\n",
      "There is currently not any PII, HIPAA, or sensitive data used in this solution.\n",
      "\n",
      "7. Analytics and Reporting \n",
      "\n",
      "The following section defines the key technologies being used to support the Amynta Group solution for Production Reporting.\n",
      "\n",
      "7.1 Analytics Platform\n",
      "\n",
      "Microsoft Fabric will serve as the foundation for all analytic workloads at Amynta Group.  It’s a comprehensive solution that provides a unified platform for data management, ingestion, transformation, and reporting.\n",
      "\n",
      "Fabric Ecosystem:\n",
      "\n",
      "OneLake – data management\n",
      "\n",
      "Data Factory – orchestration and extraction\n",
      "\n",
      "Notebooks – API extraction and data engineering\n",
      "\n",
      "Lakehouse – data manipulation\n",
      "\n",
      "Gateway – on-premise access\n",
      "\n",
      "7.3 Fabric Domains\n",
      "\n",
      "Source: ./my-docs/Amynta Group - Solution Design.docx\n",
      "Title: None\n",
      "Content: Amynta has numerous data sources containing various types of data stored in various ways. All of these data share a set of common attributes: data location, data format, can I identify new or changed data, if yes to last how do I identify the changed data, what are the keys to update for changed data. \n",
      "\n",
      "Ingesting this data into a common data repository is also a standard process: connect to the source, copy the source, write the source to bronze, merge the source to Silver. \n",
      "\n",
      "While this is an oversimplification, it is meant to demonstrate the opportunity to control the data ingestion process through a metadata framework. \n",
      "\n",
      "Ingestion Metadata\n",
      "\n",
      "The ingestion metadata is driven by 3 primary tables:  \n",
      "\n",
      "Source – connection info for the source\n",
      "\n",
      "Source_Object – details required for processing object (PKs, Incremental attributes)\n",
      "\n",
      "Object_Field – data type, column order, nullable or not\n",
      "\n",
      "4.3.1.1 Source Table\n",
      "\n",
      "Source: ./my-docs/Broker In A Box/Proposal & Contracts/Fog Solutions - Assured Partners - Broker in a Box - Proposal.pptx\n",
      "Title: None\n",
      "Content: Solutions Architect \n",
      "\n",
      "Solutions Engineer \n",
      "\n",
      "2 Sprints, 4 weeks, $40K\n",
      "\n",
      "Team\n",
      "\n",
      "Cost\n",
      "\n",
      "About Fog\n",
      "\n",
      "Why Fog Solutions?\n",
      "\n",
      "We help our clients create transformative custom AI Apps (custom Copilots) transforming the way they conduct business. \n",
      "\n",
      "To power these apps, we bring client data into a modern Lakehouse and leverage that data for maximum business impact.\n",
      "\n",
      "Service Offerings\n",
      "\n",
      "Data & Analytics Modernization\n",
      "\n",
      "Generative AI Acceleration\n",
      "\n",
      "AI Enabled Applications\n",
      "\n",
      "Data strategy aligned to modernizing your data estate by leveraging native cloud technologies and a strong partner ecosystem to enhance data collection, storage, analysis and visualization.\n",
      "\n",
      "Derive valuable insights and make informed decisions by accelerating your data science projects with expert guidance, advanced tools and streamlined processes.\n",
      "\n",
      "Bring your data to life through AI-enabled experiences such as cloud native apps, dashboard and reports, or pre-developed ML solutions for voice, text, and video.\n",
      "\n",
      "Our Understanding of AP\n",
      "\n",
      "Source: ./my-docs/Amynta Group - Solution Design.docx\n",
      "Title: None\n",
      "Content: This area is just a generic representation of various possible data sources.  It is meant to be a representation of the fact that because Fabric out of the box has over 135 native connecters the ingestion framework will be able to meet most of Amynta’s needs. For phase 1, we are processing ALIS and IMS data sources.\n",
      "\n",
      "As mentioned in preceding section, the metadata drives the ‘what’ that gets processed. The important note here in reference to the diagram is that the green symbol is shown multiple times to represent that it is used throughout the process. However, it is a single repository.\n",
      "\n",
      "This parent pipeline is primarily an orchestrator calling other processes.  It is scheduled to execute (the initial implementation is batch ingestion) with a specific source parameter being passed in as the data to be ingested.\n",
      "\n",
      "Source: ./my-docs/Amynta Group - Solution Design.docx\n",
      "Title: None\n",
      "Content: Py/Spark Notebooks: \n",
      "Fabric as a SaaS platform does not require provisioning of Spark clusters for execution.  The notebooks handle the processing from Bronze to Silver and Silver to Gold and are executed by the pipelines which pass parameters to specify what objects and actions to take.\n",
      "\n",
      "Fabric Lakehouse and OneLake: \n",
      "The medallion architecture depicted in the diagram will be within a Fabric component called a Fabric Lakehouse.  The lakehouse is a logical grouping of data that resides on Fabric OneLake which is the central repository for all data in the Fabric tenant. The OneLake is Azure ADLS Gen2, however, because Fabric is SaaS there is no provisioning of the storage accounts or containers.\n",
      "\n",
      "4.3.4 Ingestion Processing\n",
      "\n",
      "The high-level document below is well annotated to describe the general flow and processing of the ingestion framework.  Below is a quick summary.\n",
      "\n",
      "Source: ./my-docs/Amynta Group - Solution Design.docx\n",
      "Title: None\n",
      "Content: All data ingestion starts with ingestion to bronze layer so the generic ingest to bronze is called.  The only purpose of this pipeline is to establish the type of platform the source to be loaded is on and call the appropriate pipeline to load that source. \n",
      "Pipleines have some limitations to the number and ways logic control structures can be used, for example a ForEach cannot contain a ForEach. Combining IF, SWITCH (similar to a CASE or IF ELSE), with ForEach also have limits. This is why we see pipelines calling pipelines in what might seem to be extra steps.\n",
      "\n",
      "INFO:     [12:16:05] 📃 Source: ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Chubb/CHUBB.pdf\n",
      "Title: None\n",
      "Content: 3. use industry acceptable encryption technology; 4. properly apply necessary software patches; 5. maintain the performance of software so that such software: is not subject to expiration, cancellation, or withdrawal; is not released or used during its developmental state; or\n",
      "\n",
      "a. b. c. has passed all test runs and has proven successful in applicable daily operations;\n",
      "\n",
      "6. comply with any state or federal Privacy Regulations and self-regulatory requirements around minimum data security standards;\n",
      "\n",
      "and that the above activities are a necessary condition precedent to coverage for any Claim hereunder. The statements and information contained in A1 – A6 above, including all information provided concerning network security policies and procedures, information management policies and procedures, and business continuity plans and policies, are true and accurate and:\n",
      "\n",
      "Source: ./my-docs/Amynta Group - Solution Design.docx\n",
      "Title: None\n",
      "Content: Microsoft Fabric OneLake is encrypted at rest by default. Microsoft Fabric enforces enterprise-grade security measures, and encryption at rest is a fundamental aspect of its data protection strategy. The encryption is FIPS 140-2 compliant and Microsoft-managed keys are rotated appropriately. Data in transit between Microsoft services is always encrypted with at least TLS 1.2, with negotiation to TLS 1.3 when possible. Inbound OneLake communication enforces TLS 1.2 and negotiates TLS 1.3 when possible.\n",
      "\n",
      "Fabric Data Factory pipelines and Fabric Spark Notebooks are configured to utilize Azure Key Vault for secure access to encrypted data, including API tokens, usernames, and passwords. This integration ensures that sensitive information is managed and accessed securely, enhancing overall data protection within the environment.\n",
      "\n",
      "By Source:\n",
      "\n",
      "ALIS – API token \n",
      "\n",
      "IMS – SQL Server, server name, username, password\n",
      "\n",
      "6.2 Data Security Techniques\n",
      "\n",
      "Source: ./my-docs/Amynta Group - Solution Design.docx\n",
      "Title: None\n",
      "Content: The advantages of leveraging a CDM for corporate reporting, especially in a continually expanding company, are substantial. As a CDM program matures it will become the key central repository for corporate level reporting.  Over time there will be numerous dashboards and business reports created using it as the data source, many of them providing analytics across multiple business units. \n",
      "\n",
      "The following diagram illustrates the entities and keys that have been built for the initial phase of the enterprise data strategy program.\n",
      "\n",
      "6. Data Encryption and Security\n",
      "\n",
      "Encryption Methods\n",
      "\n",
      "Source: ./my-docs/Broker In A Box/Delivery/AP - Production Release Required Materials/Run Book-- template to be replicated.docx\n",
      "Title: None\n",
      "Content: 2. Compliance with Regulations: Adhere to Data Protection Laws: Familiarize yourself with relevant regulations such as GDPR, CCPA, and HIPAA. Ensure that your RPA processes comply with these laws, particularly regarding data collection, processing, and storage.\n",
      "\n",
      "3. Data Minimization: Limit Data Collection: Only collect and process the minimum amount of PII necessary for the automation task. This reduces the risk of exposure and simplifies compliance efforts.\n",
      "\n",
      "4. Access Controls: Implement Role-Based Access: Ensure that only authorized personnel and bots have access to PII. Use role-based access controls to restrict data access based on user roles and responsibilities.\n",
      "\n",
      "5. Data Encryption: Secure Data at Rest and in Transit: Use encryption to protect PII both when it is stored and during transmission. This adds an additional layer of security against unauthorized access.\n",
      "\n",
      "Source: ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Hanover/HANOVER 1_CP.pdf\n",
      "Title: None\n",
      "Content: F26 H833395 01 1902787 821-0002 08 19Includes copyrighted materials of Insurance Services Office, Inc. with its permission.Page 8 of 63Copyright 2019 The Hanover Insurance Company. All Rights Reserved.necessary “suspension” of your “operations” at the described premises during the “cloud computing services period of restoration” due to an interruption in “cloud computing services” to you from your cloud provider caused by the following: (a)Direct physical loss of or damage to property at the premises of your cloud provider; or(b)Destruction or corruption of your \"electronic data\" that is stored within your cloud service provider’s “network”. The loss or damage must be caused by or result from “electronic vandalism” or a Covered Cause of Loss. The destruction or corruption of your “electronic data” can originate from a person located anywhere in the world.(2)“Cloud computing services” must be provided by a professional provider with whom you have a contract. (3)The most we will pay\n",
      "\n",
      "Source: ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/Test Policy - 10 - T40048431.pdf\n",
      "Title: None\n",
      "Content: Confidential Information loss or unauthorized use of confidential information of any kind including trade secrets, patents, processing methods, or customer lists, whether such confidential information is yours or others.\n",
      "\n",
      "(e)\n",
      "\n",
      "Cryptocurrency loss of or damage to cryptocurrency.\n",
      "\n",
      "(f)\n",
      "\n",
      "Custody loss of or damage to money, securities, or property while in the custody of any custodian, unless the loss or damage is in excess of the amount you recover under any contract with or insurance carried by such custodian.\n",
      "\n",
      "(g)\n",
      "\n",
      "Data Security Breach Expenses loss arising from a data security breach including: (i) (ii)\n",
      "\n",
      "forensic audit expenses; fines, penalties, or expenses to comply with Payment Card Industry Data Security Standard or such similar federal and state laws, statutes, or standards; notification expenses to individuals whose personal information may have been stolen, accessed, downloaded or misappropriated while in the insured entity’s care, custody or control.\n",
      "\n",
      "(iii)\n",
      "\n",
      "Source: ./my-docs/Broker In A Box/Client Supplied/Testing PDF Documents/Commercial Package Policies/CNA/CNA 1_CRM.pdf\n",
      "Title: None\n",
      "Content: Confidential Information loss or unauthorized use of confidential information of any kind including trade secrets, patents, processing methods, or customer lists, whether such confidential information is yours or others.\n",
      "\n",
      "(e)\n",
      "\n",
      "Cryptocurrency loss of or damage to cryptocurrency.\n",
      "\n",
      "(f)\n",
      "\n",
      "Custody loss of or damage to money, securities, or property while in the custody of any custodian, unless the loss or damage is in excess of the amount you recover under any contract with or insurance carried by such custodian.\n",
      "\n",
      "(g)\n",
      "\n",
      "Data Security Breach Expenses loss arising from a data security breach including: (i) (ii)\n",
      "\n",
      "forensic audit expenses; fines, penalties, or expenses to comply with Payment Card Industry Data Security Standard or such similar federal and state laws, statutes, or standards; notification expenses to individuals whose personal information may have been stolen, accessed, downloaded or misappropriated while in the insured entity’s care, custody or control.\n",
      "\n",
      "(iii)\n",
      "\n",
      "Source: ./my-docs/Amynta Group - Solution Design.docx\n",
      "Title: None\n",
      "Content: 3. User Roles and Security Considerations\n",
      "\n",
      "Microsoft Fabric supports a range of security measures to control what features of the workspace users have access to, and who can read or modify what data. \n",
      "\n",
      "In general, the following are recommended: \n",
      "\n",
      "Leverage the medallion architecture to curate and combine common data across varying sources, securing access to roles that need access to each medallion layer, via separate Lakehouses\n",
      "\n",
      "Use of Azure Key Vault for securing credentials that Pipelines and Notebooks via Entra Service Principal/Workspace Identity\n",
      "\n",
      "Use of Workspace Access Control to control who can view or run which notebooks and view data in the Gold layer\n",
      "\n",
      "Leverage Direct-Lake for handling varying source refresh times using Row-Level Security (RLS) for varying departmental data security\n",
      "\n",
      "3.1 Definition of User Roles\n",
      "\n",
      "Specific roles will be leveraged by configuring Entra Groups to each role. The following roles and groups will be leveraged for the implementation:\n",
      "\n",
      "INFO:     [12:16:05] 📃 Source: ./my-docs/Amynta Group - Solution Design.docx\n",
      "Title: None\n",
      "Content: 8. DevOps Integration\n",
      "\n",
      "8.1 Source Control Management \n",
      "\n",
      "The Development Process will leverage Azure DevOps and be fully integrated into the environment named workspaces.  Leveraging Fabric Deployment Pipelines for moving code and artifacts from DEV through to PROD environments.  For this project infrastructure external to Fabric, such as Key Vault, is managed through manual operations. Production Reporting follows these guidelines: \n",
      "\n",
      "Feature/User DEV: Iterative development environment where engineers test code on branches. No guarantees are made about reliability in this environment without consistent branching. Developers are responsible for keeping their branches in sync with the Main branch/workspace, in their Feature Workspace. Developers will submit pull requests (PR’s) to merge code into the Main branch.\n",
      "\n",
      "DEV: Development workspace where new code and changes will be unit tested by developers before promoting to UAT. This is the primary workspace for the Main branch.\n",
      "\n",
      "Source: ./my-docs/Broker In A Box/ARB Review/Assured Partners ARB Questionnaire.xlsx\n",
      "Title: None\n",
      "Content: Application code is stored on Azure DevOps Repos - Deployment to Azure is managed using CI CD - Pipelines and Releases feature of the Service\n",
      "\n",
      "What is the fully deployed user count (incremental or full scale rollout)?\n",
      "\n",
      "What is the support agreement with the Vendor?\n",
      "\n",
      "Vendor is embedded with the AP team during the pilot phase and will provide support as needed, a formal agreement can follow this first phase\n",
      "\n",
      "What are the SLAs with the Vendor?\n",
      "\n",
      "No contractual SLAs at this time for the initial pilot phase, formal SLA and support to follow the pilot.\n",
      "\n",
      "Will this be supported by the AP Service Desk?\n",
      "\n",
      "Yes\n",
      "\n",
      "What are the escalation contacts with the Vendor (TAM, CSM etc.)?\n",
      "\n",
      "To be provided\n",
      "\n",
      "OTHER COMMENTS:\n",
      "\n",
      "Request For Architecture Review\n",
      "\n",
      "SUMMARY\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "MINOR\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "MAJOR\n",
      "\n",
      "Source: ./my-docs/Broker In A Box/Delivery/AP - Production Release Required Materials/SOP - Broker in a Box - FOG DRAFT - 120924.docx\n",
      "Title: None\n",
      "Content: This Standard Operating Procedure (SOP) outlines the best practices for managing the \"Broker in a Box\" web application deployed in the company’s Microsoft Azure cloud infrastructure. The document provides step-by-step guidance to ensure efficient, secure, and reliable operation.\n",
      "\n",
      "1.2 Audience\n",
      "\n",
      "This SOP applies to all team members involved in the deployment, maintenance, and management of the \"Broker in a Box\" application within the company’s Azure environment.\n",
      "\n",
      "1.3 Overview\n",
      "\n",
      "This SOP includes guidance for operations such as deployment, monitoring, troubleshooting, scaling, and security management. The application leverages key Azure services for robust performance and scalability.\n",
      "\n",
      "1.4 Assumptions\n",
      "\n",
      "The team has access to Azure resources and proper permissions.\n",
      "\n",
      "The application follows industry best practices for cloud deployments.\n",
      "\n",
      "1.5 Change Control\n",
      "\n",
      "All changes to this SOP must be reviewed and approved by the Application Owner.\n",
      "\n",
      "Source: ./my-docs/Amynta Group - Solution Design.docx\n",
      "Title: None\n",
      "Content: 8.3 Backward Compatibility Strategies\n",
      "\n",
      "Azure DevOps facilitates branch reversion for quick rollbacks. For data recovery, Delta Time Travel/Restore is employed to revert datasets to a specific point in time, matching the branch timestamp, and ensuring minimal disruption. This combination allows efficient and reliable recovery of both code and data in the event of an issue.\n",
      "\n",
      "9. Cloud Fundamentals/Readiness Recommendations\n",
      "\n",
      "Fog Solutions was not responsible for the Azure Landing zone and since the data for Production Reporting is not sensitive or requires additional security, Amynta Group elected to wait to implement a true Azure Landing Zone architecture, but Fog made the following recommendations.\n",
      "\n",
      "9.1 Azure Region\n",
      "\n",
      "Source: ./my-docs/Broker In A Box/Delivery/AP - Production Release Required Materials/SOP - Broker in a Box - FOG DRAFT - 120924.docx\n",
      "Title: None\n",
      "Content: Ensure sensitive configurations in infra/secrets.json (e.g., SQL admin password, Okta settings) are correctly set up and stored in Azure Key Vault.\n",
      "\n",
      "Deploy Application\n",
      "\n",
      "Use the local deployment script (infra/deploy-local.sh) for initial testing:\n",
      "\n",
      "Builds backend and frontend Docker images.\n",
      "\n",
      "Tags images with the version or latest.\n",
      "\n",
      "Pushes images to Azure Container Registry.\n",
      "\n",
      "Trigger the deployment pipeline via CI/CD tools (e.g., Azure DevOps, GitHub Actions).\n",
      "\n",
      "Pipeline Details:\n",
      "\n",
      "Uses ubuntu-latest as the build environment.\n",
      "\n",
      "Specifies key pipeline variables:\n",
      "\n",
      "resourceGroup: ASP-D-BIB-RG-01\n",
      "\n",
      "acrName: aspdbibacr01\n",
      "\n",
      "azureSubscription: GenAI_BIB_DEV\n",
      "\n",
      "Includes a \"Build\" stage for compiling and packaging the application.\n",
      "\n",
      "\n",
      "\n",
      "Validate deployment using smoke tests.\n",
      "\n",
      "Post-Deployment Verification\n",
      "\n",
      "Check application health endpoints.\n",
      "\n",
      "Verify key functionality.\n",
      "\n",
      "Monitor initial metrics (e.g., CPU usage, response time).\n",
      "\n",
      "3.2 Monitoring and Alerts\n",
      "\n",
      "Set Up Monitoring\n",
      "\n",
      "Source: ./my-docs/Broker In A Box/ARB Review/Assured Partners current ARB Questionnaire_PolicyPal.xlsx\n",
      "Title: None\n",
      "Content: Are there similar, related or competing projects with this request?\n",
      "\n",
      "Currently - Not available\n",
      "\n",
      "Are all prerequisists and/or specifications incuded current?\n",
      "\n",
      "Yes\n",
      "\n",
      "Request For Architecture Review\n",
      "\n",
      "HOW WILL THIS BE DONE?\n",
      "\n",
      "Is Developer access needed?\n",
      "\n",
      "Yes\n",
      "\n",
      "What is the Deployment strategy?\n",
      "\n",
      "Application code is stored on Azure DevOps Repos - Deployment to Azure is managed using CI CD - Pipelines and Releases feature of the Service\n",
      "\n",
      "What is the fully deployed user count (incremental or full scale rollout)?\n",
      "\n",
      "10 users\n",
      "\n",
      "What is the support agreement with the Vendor?\n",
      "\n",
      "MS Azure - Cloud Service Provider   LTIM Team - Network Support\n",
      "\n",
      "What are the SLAs with the Vendor?\n",
      "\n",
      "P2 - 4 hours,  P3 - 1 day\n",
      "\n",
      "Will this be supported by the AP Service Desk?\n",
      "\n",
      "Yes\n",
      "\n",
      "What are the escalation contacts with the Vendor (TAM, CSM etc.)?\n",
      "\n",
      "MS Azure - <Charlie Hopkins>    LTIM- Vishal M\n",
      "\n",
      "Source: ./my-docs/Broker In A Box/Proposal & Contracts/AssuredPartners - Fog Solutions - Broker in a Box - AP Formated SOW - Fully Executed.pdf\n",
      "Title: None\n",
      "Content: The Engagement Leader will deliver regular status reports that communicate activities and deliverables completed, issues or risks that have arisen, and any changes to scope that have occurred during the reporting period. These status reports will be delivered in accordance with the Sprint schedule. Work Location\n",
      "\n",
      "All work will be performed remotely, apart from in-person workshops to gather requirements and review deliverables as appropriate.\n",
      "\n",
      "3. Responsibilities and Assumptions\n",
      "\n",
      "During the project, client is responsible for:\n",
      "\n",
      "\n",
      "\n",
      "Partnering with Fog Solutions in setting up the infrastructure within dev Azure tenant.\n",
      "\n",
      "\n",
      "\n",
      "Providing UX and UI Design support for up to 10 hours per week in sprints 2 through 6.\n",
      "\n",
      "\n",
      "\n",
      "Providing Product Management support including the development of epics, user stories and acceptance criteria up to 20 hours per week through sprints 1 through 6.\n",
      "\n",
      "Deploying solution to production Azure tenant.\n",
      "\n",
      "\n",
      "\n",
      "Securing the source data and Azure environments.\n",
      "\n",
      "Source: ./my-docs/Broker In A Box/Delivery/AP - Production Release Required Materials/SOP - Broker in a Box - FOG DRAFT - 120924.docx\n",
      "Title: None\n",
      "Content: Standard Operating Procedure (SOP) for Broker in a Box\n",
      "\n",
      "Document Revision History\n",
      "\n",
      "Version Date (mm-dd-yyyy) Sections Changed By Comments 1 12-09-2024 All Fog Solutions Draft for first review with AP team\n",
      "\n",
      "Table of Contents\n",
      "\n",
      "Introduction\n",
      "\n",
      "1.1 Purpose\n",
      "\n",
      "1.2 Audience\n",
      "\n",
      "1.3 Overview\n",
      "\n",
      "1.4 Assumptions\n",
      "\n",
      "1.5 Change Control\n",
      "\n",
      "1.6 Additional Notes & Tips\n",
      "\n",
      "1.7 Audit\n",
      "\n",
      "1.8 Communication\n",
      "\n",
      "1.9 Reference Documents\n",
      "\n",
      "Design\n",
      "\n",
      "2.1 Azure Services Overview\n",
      "\n",
      "2.2 Architecture Diagram and Description\n",
      "\n",
      "2.3 Type Definitions\n",
      "\n",
      "Procedures\n",
      "\n",
      "3.1 Deployment\n",
      "\n",
      "3.2 Monitoring and Alerts\n",
      "\n",
      "3.3 Scaling\n",
      "\n",
      "3.4 Security Management\n",
      "\n",
      "3.5 Troubleshooting\n",
      "\n",
      "3.6 Development Setup\n",
      "\n",
      "Rollback (Failed)\n",
      "\n",
      "IT Contact Details\n",
      "\n",
      "Maintenance\n",
      "\n",
      "Appendix\n",
      "\n",
      "\n",
      "\n",
      "1. Introduction\n",
      "\n",
      "1.1 Purpose\n",
      "\n",
      "INFO:     [12:16:05] Finalized research step.\n",
      "💸 Total Research Costs: $0.007845000000000001\n",
      "INFO:     [12:16:05] ✍️ Writing report for '\n",
      "You are to create a design document that describes, in detail, a solutions design for Assured Partners Broker in a box.\n",
      "\n",
      "Use the sections provided to create a detailed report.  Each section should be expanded to include as much detail as possible.  Use the internet to expand on recommended practices.\n",
      "\n",
      "Be verbose and expand and topics as much as possible.  If the vecttor_store provided doesn't have informmation, state would should be in each sub topic provided.\n",
      "\n",
      "Do not mention anything about Amynta, but assume the Broker in the box data fabric implmentation is similar.\n",
      "\n",
      "Use the internet to expand on recommended practices.\n",
      "\n",
      "The report sections should be as follows:\n",
      "\n",
      "\"Project Summary\", \"Scope of the Solution\", \"Stakeholders and Audiences\", \"Solution Design Overview\", \"User Roles and Security Considerations\", \"Definition of User Roles\", \"Data Sources and Ingestion\", \"Data Ingestion Strategy\", \"Data Storage and Management\", \"Storage Solutions\", \"Data Retention and Archival Policies\", \"Data Encryption and Data Security\", \"Encryption Methods\", \"Data Security Techniques\", \"Analytics and Reporting\", \"Reporting\", \"Analytics Services\", \"DevOps Integration\", \"Source Control Management\", \"Code Deployment and Management Processes\", \"Rollback Strategies\", \"Cloud Fundamentals/Readiness\", \"Regional Planning and Data Center Utilization\", \"Network and Infrastructure Setup\", \"Azure Resources\", \"Network\", \"Identity and Access Management\", \"Cost Optimization and Governance\", \"Backup and Recovery Solutions\", \"High Availability/Disaster Recovery Plan\", \"Monitoring and Alert Systems\", \"Appendix and References\", \"Glossary of Terms\", \"Reference Documents\"\n",
      "\n",
      "\n",
      "'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m# Solution Design Document for Assured Partners Broker in a Box\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m---\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m## **Project Summary**\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32mThe \"Broker in a Box\" project is a transformative initiative aimed at modernizing and streamlining insurance brokerage operations for Assured Partners (AP). The solution leverages cutting-edge technologies such as Microsoft Fabric, Azure cloud services, and AI-driven insights to create a scalable, secure, and efficient platform. The primary objective is to provide brokers with a unified platform for policy management, rule-based decision-making, and enhanced customer interactions. By integrating advanced data ingestion, analytics, and reporting capabilities, the solution ensures operational excellence and compliance with industry standards.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32mThe project is structured into multiple sprints, each focusing on iterative development, testing, and deployment of features. Key deliverables include user authentication via Okta, policy data integration, AI-powered recommendations, and robust reporting capabilities. The solution also incorporates a medallion architecture for data management, ensuring data consistency and security across the platform.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m---\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m## **Scope of the Solution**\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32mThe scope of the \"Broker in a Box\" solution includes the following:\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m1. **Core Functionalities**:\n",
      "\u001b[0m\n",
      "\u001b[32m   - Policy data ingestion and management.\n",
      "\u001b[0m\n",
      "\u001b[32m   - Rule-based decision-making and policy reviews.\n",
      "\u001b[0m\n",
      "\u001b[32m   - AI-driven recommendations for brokers.\n",
      "\u001b[0m\n",
      "\u001b[32m   - Role-based access control for secure data handling.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m2. **Technology Stack**:\n",
      "\u001b[0m\n",
      "\u001b[32m   - Microsoft Fabric for data management and analytics.\n",
      "\u001b[0m\n",
      "\u001b[32m   - Azure cloud services for hosting and scalability.\n",
      "\u001b[0m\n",
      "\u001b[32m   - Integration with Applied Epic SOAP for policy data retrieval.\n",
      "\u001b[0m\n",
      "\u001b[32m   - Okta for user authentication.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m3. **Deployment and Maintenance**:\n",
      "\u001b[0m\n",
      "\u001b[32m   - CI/CD pipelines for seamless deployment.\n",
      "\u001b[0m\n",
      "\u001b[32m   - Monitoring and alert systems for proactive issue resolution.\n",
      "\u001b[0m\n",
      "\u001b[32m   - High availability and disaster recovery mechanisms.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m4. **Compliance and Security**:\n",
      "\u001b[0m\n",
      "\u001b[32m   - Adherence to GDPR, CCPA, and HIPAA regulations.\n",
      "\u001b[0m\n",
      "\u001b[32m   - Encryption of data at rest and in transit.\n",
      "\u001b[0m\n",
      "\u001b[32m   - Role-based access control and auditing.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m5. **Stakeholder Engagement**:\n",
      "\u001b[0m\n",
      "\u001b[32m   - Regular status updates and feedback sessions.\n",
      "\u001b[0m\n",
      "\u001b[32m   - Workshops for requirements gathering and design reviews.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m---\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m## **Stakeholders and Audiences**\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m### **Primary Stakeholders**:\n",
      "\u001b[0m\n",
      "\u001b[32m- **Assured Partners Leadership**: Responsible for strategic oversight and funding.\n",
      "\u001b[0m\n",
      "\u001b[32m- **Fog Solutions Team**: Implementation partner providing technical expertise.\n",
      "\u001b[0m\n",
      "\u001b[32m- **AP Business Teams**: End-users of the solution, including brokers and claims associates.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m### **Secondary Stakeholders**:\n",
      "\u001b[0m\n",
      "\u001b[32m- **IT Teams**: Responsible for infrastructure setup and maintenance.\n",
      "\u001b[0m\n",
      "\u001b[32m- **Compliance Officers**: Ensure adherence to data protection and privacy regulations.\n",
      "\u001b[0m\n",
      "\u001b[32m- **Customers**: Indirect beneficiaries of improved brokerage services.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m---\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m## **Solution Design Overview**\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32mThe \"Broker in a Box\" solution is designed to be a modular, scalable, and secure platform. It employs a medallion architecture for data management, with distinct layers for raw (bronze), cleaned (silver), and curated (gold) data. The solution integrates seamlessly with existing AP systems and third-party services, ensuring minimal disruption to current workflows.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m### **Key Components**:\n",
      "\u001b[0m\n",
      "\u001b[32m1. **Data Ingestion Layer**:\n",
      "\u001b[0m\n",
      "\u001b[32m   - Fabric Data Factory pipelines for orchestrating data ingestion.\n",
      "\u001b[0m\n",
      "\u001b[32m   - Integration with APIs, SQL databases, and CSV files.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m2. **Data Management Layer**:\n",
      "\u001b[0m\n",
      "\u001b[32m   - Fabric Lakehouse for centralized data storage.\n",
      "\u001b[0m\n",
      "\u001b[32m   - Metadata-driven ingestion framework for flexibility and scalability.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m3. **Application Layer**:\n",
      "\u001b[0m\n",
      "\u001b[32m   - Frontend and backend components built using Angular and C#.\n",
      "\u001b[0m\n",
      "\u001b[32m   - Dockerized deployment for portability and consistency.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m4. **Security Layer**:\n",
      "\u001b[0m\n",
      "\u001b[32m   - Azure Key Vault for managing sensitive credentials.\n",
      "\u001b[0m\n",
      "\u001b[32m   - Role-based access control and auditing.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m---\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m## **User Roles and Security Considerations**\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m### **Security Best Practices**:\n",
      "\u001b[0m\n",
      "\u001b[32m- **Role-Based Access Control (RBAC)**: Restrict access to data and features based on user roles.\n",
      "\u001b[0m\n",
      "\u001b[32m- **Data Encryption**: Encrypt data at rest using FIPS 140-2 compliant methods and in transit using TLS 1.2/1.3.\n",
      "\u001b[0m\n",
      "\u001b[32m- **Audit Trails**: Maintain logs of user activities for compliance and troubleshooting.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m### **Potential Risks**:\n",
      "\u001b[0m\n",
      "\u001b[32m- Unauthorized access to sensitive data.\n",
      "\u001b[0m\n",
      "\u001b[32m- Data breaches due to inadequate encryption.\n",
      "\u001b[0m\n",
      "\u001b[32m- Misuse of AI-generated recommendations.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m---\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m## **Definition of User Roles**\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m1. **System Administrators**:\n",
      "\u001b[0m\n",
      "\u001b[32m   - Manage infrastructure and deployments.\n",
      "\u001b[0m\n",
      "\u001b[32m   - Monitor system performance and security.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m2. **Brokers**:\n",
      "\u001b[0m\n",
      "\u001b[32m   - Access policy data and AI recommendations.\n",
      "\u001b[0m\n",
      "\u001b[32m   - Perform rule-based policy reviews.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m3. **Claims Associates**:\n",
      "\u001b[0m\n",
      "\u001b[32m   - Engage in policy chat sessions for claims processing.\n",
      "\u001b[0m\n",
      "\u001b[32m   - Collaborate with brokers on policy-related queries.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m4. **Developers**:\n",
      "\u001b[0m\n",
      "\u001b[32m   - Develop and maintain application features.\n",
      "\u001b[0m\n",
      "\u001b[32m   - Implement CI/CD pipelines and resolve issues.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m5. **Compliance Officers**:\n",
      "\u001b[0m\n",
      "\u001b[32m   - Monitor adherence to data protection regulations.\n",
      "\u001b[0m\n",
      "\u001b[32m   - Review audit logs and security reports.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m---\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m## **Data Sources and Ingestion**\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m### **Data Sources**:\n",
      "\u001b[0m\n",
      "\u001b[32m- **Applied Epic SOAP**: For policy data retrieval.\n",
      "\u001b[0m\n",
      "\u001b[32m- **SQL Databases**: For structured data storage.\n",
      "\u001b[0m\n",
      "\u001b[32m- **APIM and Logic Apps**: For API-based data ingestion.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m### **Data Ingestion Strategy**:\n",
      "\u001b[0m\n",
      "\u001b[32m- Use Fabric Data Factory pipelines for orchestrating data ingestion.\n",
      "\u001b[0m\n",
      "\u001b[32m- Leverage metadata-driven frameworks for flexibility.\n",
      "\u001b[0m\n",
      "\u001b[32m- Perform daily data ingestion to ensure up-to-date information.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m---\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m## **Data Storage and Management**\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m### **Storage Solutions**:\n",
      "\u001b[0m\n",
      "\u001b[32m- **Fabric Lakehouse**: Centralized storage for all data layers.\n",
      "\u001b[0m\n",
      "\u001b[32m- **OneLake**: Azure ADLS Gen2-based storage for scalability and security.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m### **Data Retention and Archival Policies**:\n",
      "\u001b[0m\n",
      "\u001b[32m- Retain raw data for 90 days in the bronze layer.\n",
      "\u001b[0m\n",
      "\u001b[32m- Archive curated data in the gold layer for up to 7 years.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m---\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m## **Data Encryption and Data Security**\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m### **Encryption Methods**:\n",
      "\u001b[0m\n",
      "\u001b[32m- **At Rest**: FIPS 140-2 compliant encryption using Microsoft-managed keys.\n",
      "\u001b[0m\n",
      "\u001b[32m- **In Transit**: TLS 1.2/1.3 for secure data transmission.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m### **Data Security Techniques**:\n",
      "\u001b[0m\n",
      "\u001b[32m- Use Azure Key Vault for managing credentials.\n",
      "\u001b[0m\n",
      "\u001b[32m- Implement Row-Level Security (RLS) for departmental data segregation.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m---\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m## **Analytics and Reporting**\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m### **Reporting**:\n",
      "\u001b[0m\n",
      "\u001b[32m- Use Power BI for interactive dashboards and reports.\n",
      "\u001b[0m\n",
      "\u001b[32m- Generate daily and monthly reports for policy reviews and AI recommendations.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m### **Analytics Services**:\n",
      "\u001b[0m\n",
      "\u001b[32m- Leverage Fabric Notebooks for data engineering and analysis.\n",
      "\u001b[0m\n",
      "\u001b[32m- Use AI models for generating actionable insights.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m---\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m## **DevOps Integration**\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m### **Source Control Management**:\n",
      "\u001b[0m\n",
      "\u001b[32m- Use Azure DevOps Repos for version control.\n",
      "\u001b[0m\n",
      "\u001b[32m- Implement branching strategies for feature development and bug fixes.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m### **Code Deployment and Management Processes**:\n",
      "\u001b[0m\n",
      "\u001b[32m- Use CI/CD pipelines for automated deployments.\n",
      "\u001b[0m\n",
      "\u001b[32m- Perform smoke tests post-deployment to ensure functionality.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m### **Rollback Strategies**:\n",
      "\u001b[0m\n",
      "\u001b[32m- Use Delta Time Travel for data rollback.\n",
      "\u001b[0m\n",
      "\u001b[32m- Revert code changes using Azure DevOps branch reversion.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m---\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m## **Cloud Fundamentals/Readiness**\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m### **Regional Planning and Data Center Utilization**:\n",
      "\u001b[0m\n",
      "\u001b[32m- Deploy resources in Azure regions closest to major AP offices.\n",
      "\u001b[0m\n",
      "\u001b[32m- Use availability zones for high availability.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m### **Network and Infrastructure Setup**:\n",
      "\u001b[0m\n",
      "\u001b[32m- Use Azure Virtual Network for secure communication.\n",
      "\u001b[0m\n",
      "\u001b[32m- Implement Azure Firewall for traffic filtering.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m---\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m## **Cost Optimization and Governance**\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m- Use Azure Cost Management for monitoring expenses.\n",
      "\u001b[0m\n",
      "\u001b[32m- Implement tagging policies for resource tracking.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m---\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m## **Backup and Recovery Solutions**\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m- Use Azure Backup for regular snapshots.\n",
      "\u001b[0m\n",
      "\u001b[32m- Implement disaster recovery plans with a Recovery Time Objective (RTO) of 4 hours.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m---\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m## **High Availability/Disaster Recovery Plan**\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m- Deploy resources across multiple availability zones.\n",
      "\u001b[0m\n",
      "\u001b[32m- Use Azure Site Recovery for failover capabilities.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m---\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m## **Monitoring and Alert Systems**\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m- Use Azure Monitor for tracking metrics and logs.\n",
      "\u001b[0m\n",
      "\u001b[32m- Set up alerts for critical issues such as downtime or security breaches.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m---\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m## **Appendix and References**\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m### **Glossary of Terms**:\n",
      "\u001b[0m\n",
      "\u001b[32m- **RBAC**: Role-Based Access Control.\n",
      "\u001b[0m\n",
      "\u001b[32m- **RLS**: Row-Level Security.\n",
      "\u001b[0m\n",
      "\u001b[32m- **CI/CD**: Continuous Integration/Continuous Deployment.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m### **Reference Documents**:\n",
      "\u001b[0m\n",
      "\u001b[32m- \"AP - Production Release Required Materials\"\n",
      "\u001b[0m\n",
      "\u001b[32m- \"Broker in a Box - SOP\"\n",
      "\u001b[0m\n",
      "\u001b[32m- \"Assured Partners - Fog Solutions - Broker in a Box - SOW\"\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m---\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m## **References**\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m- Microsoft Fabric Documentation. Retrieved from https://learn.microsoft.com/en-us/fabric/\n",
      "\u001b[0m\n",
      "\u001b[32m- Azure DevOps Documentation. Retrieved from https://learn.microsoft.com/en-us/azure/devops/\n",
      "\u001b[0m\n",
      "\u001b[32m- Azure Key Vault Documentation. Retrieved from https://learn.microsoft.com/en-us/azure/key-vault/\n",
      "\u001b[0m\n",
      "\u001b[32m- Source: ./my-docs/Broker In A Box/Delivery/AP - Production Release Required Materials/SOP - Broker in a Box - FOG DRAFT - 120924.docx\n",
      "\u001b[0m\n",
      "\u001b[32m- Source: ./my-docs/Broker In A Box/Proposal & Contracts/AssuredPartners - Fog Solutions - Broker in a Box - AP Formated SOW - Fully Executed.pdf\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     [12:16:32] 📝 Report written for '\n",
      "You are to create a design document that describes, in detail, a solutions design for Assured Partners Broker in a box.\n",
      "\n",
      "Use the sections provided to create a detailed report.  Each section should be expanded to include as much detail as possible.  Use the internet to expand on recommended practices.\n",
      "\n",
      "Be verbose and expand and topics as much as possible.  If the vecttor_store provided doesn't have informmation, state would should be in each sub topic provided.\n",
      "\n",
      "Do not mention anything about Amynta, but assume the Broker in the box data fabric implmentation is similar.\n",
      "\n",
      "Use the internet to expand on recommended practices.\n",
      "\n",
      "The report sections should be as follows:\n",
      "\n",
      "\"Project Summary\", \"Scope of the Solution\", \"Stakeholders and Audiences\", \"Solution Design Overview\", \"User Roles and Security Considerations\", \"Definition of User Roles\", \"Data Sources and Ingestion\", \"Data Ingestion Strategy\", \"Data Storage and Management\", \"Storage Solutions\", \"Data Retention and Archival Policies\", \"Data Encryption and Data Security\", \"Encryption Methods\", \"Data Security Techniques\", \"Analytics and Reporting\", \"Reporting\", \"Analytics Services\", \"DevOps Integration\", \"Source Control Management\", \"Code Deployment and Management Processes\", \"Rollback Strategies\", \"Cloud Fundamentals/Readiness\", \"Regional Planning and Data Center Utilization\", \"Network and Infrastructure Setup\", \"Azure Resources\", \"Network\", \"Identity and Access Management\", \"Cost Optimization and Governance\", \"Backup and Recovery Solutions\", \"High Availability/Disaster Recovery Plan\", \"Monitoring and Alert Systems\", \"Appendix and References\", \"Glossary of Terms\", \"Reference Documents\"\n",
      "\n",
      "\n",
      "'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m- Source: ./my-docs/Broker In A Box/Delivery/Status updates/Assured Partners - Broker in a Box Sprint 10 Mid-Sprint - 022125.pptx\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from gpt_researcher import GPTResearcher\n",
    "from gpt_researcher.utils.enum import ReportType, ReportSource, Tone\n",
    "\n",
    "new_vector_store = FAISS.load_local(\"faiss_index\", embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "sections = [ \"Project Summary\", \"Scope of the Solution\", \"Stakeholders and Audiences\", \"Solution Design Overview\", \"User Roles and Security Considerations\", \"Definition of User Roles\", \"Data Sources and Ingestion\", \"Data Ingestion Strategy\", \"Data Storage and Management\", \"Storage Solutions\", \"Data Retention and Archival Policies\", \"Data Encryption and Data Security\", \"Encryption Methods\", \"Data Security Techniques\", \"Analytics and Reporting\", \"Reporting\", \"Analytics Services\", \"DevOps Integration\", \"Source Control Management\", \"Code Deployment and Management Processes\", \"Rollback Strategies\", \"Cloud Fundamentals/Readiness\", \"Regional Planning and Data Center Utilization\", \"Network and Infrastructure Setup\", \"Azure Resources\", \"Network\", \"Identity and Access Management\", \"Cost Optimization and Governance\", \"Backup and Recovery Solutions\", \"High Availability/Disaster Recovery Plan\", \"Monitoring and Alert Systems\", \"Appendix and References\", \"Glossary of Terms\", \"Reference Documents\"]\n",
    "\n",
    "query = f\"\"\"\n",
    "You are to create a design document that describes, in detail, a solutions design for Assured Partners Broker in a box.\n",
    "\n",
    "Use the sections provided to create a detailed report.  Each section should be expanded to include as much detail as possible.  Use the internet to expand on recommended practices.\n",
    "\n",
    "Be verbose and expand and topics as much as possible.  If the vecttor_store provided doesn't have informmation, state would should be in each sub topic provided.\n",
    "\n",
    "Do not mention anything about Amynta, but assume the Broker in the box data fabric implmentation is the same.\n",
    "\n",
    "Use the internet to expand on recommended practices.\n",
    "\n",
    "The report sections should be as follows:\n",
    "\n",
    "\"Project Summary\", \"Scope of the Solution\", \"Stakeholders and Audiences\", \"Solution Design Overview\", \"User Roles and Security Considerations\", \"Definition of User Roles\", \"Data Sources and Ingestion\", \"Data Ingestion Strategy\", \"Data Storage and Management\", \"Storage Solutions\", \"Data Retention and Archival Policies\", \"Data Encryption and Data Security\", \"Encryption Methods\", \"Data Security Techniques\", \"Analytics and Reporting\", \"Reporting\", \"Analytics Services\", \"DevOps Integration\", \"Source Control Management\", \"Code Deployment and Management Processes\", \"Rollback Strategies\", \"Cloud Fundamentals/Readiness\", \"Regional Planning and Data Center Utilization\", \"Network and Infrastructure Setup\", \"Azure Resources\", \"Network\", \"Identity and Access Management\", \"Cost Optimization and Governance\", \"Backup and Recovery Solutions\", \"High Availability/Disaster Recovery Plan\", \"Monitoring and Alert Systems\", \"Appendix and References\", \"Glossary of Terms\", \"Reference Documents\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "researcher = GPTResearcher(\n",
    "    query=query, \n",
    "    report_type=ReportType.Technical, \n",
    "    report_format=\"markdown\", \n",
    "    report_source=\"langchain_vectorstore\", \n",
    "    tone=Tone.Descriptive, \n",
    "    source_urls=None, \n",
    "    document_urls=None,\n",
    "    vector_store=vector_store,\n",
    "    query_domains=[], \n",
    "    subtopics=None)\n",
    "\n",
    "research_result = await researcher.conduct_research()\n",
    "\n",
    "report = await researcher.write_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Solution Design Document for Assured Partners Broker in a Box\n",
      "\n",
      "---\n",
      "\n",
      "## **Project Summary**\n",
      "\n",
      "The \"Broker in a Box\" project is a transformative initiative aimed at modernizing and streamlining insurance brokerage operations for Assured Partners (AP). The solution leverages cutting-edge technologies such as Microsoft Fabric, Azure cloud services, and AI-driven insights to create a scalable, secure, and efficient platform. The primary objective is to provide brokers with a unified platform for policy management, rule-based decision-making, and enhanced customer interactions. By integrating advanced data ingestion, analytics, and reporting capabilities, the solution ensures operational excellence and compliance with industry standards.\n",
      "\n",
      "The project is structured into multiple sprints, each focusing on iterative development, testing, and deployment of features. Key deliverables include user authentication via Okta, policy data integration, AI-powered recommendations, and robust reporting capabilities. The solution also incorporates a medallion architecture for data management, ensuring data consistency and security across the platform.\n",
      "\n",
      "---\n",
      "\n",
      "## **Scope of the Solution**\n",
      "\n",
      "The scope of the \"Broker in a Box\" solution includes the following:\n",
      "\n",
      "1. **Core Functionalities**:\n",
      "   - Policy data ingestion and management.\n",
      "   - Rule-based decision-making and policy reviews.\n",
      "   - AI-driven recommendations for brokers.\n",
      "   - Role-based access control for secure data handling.\n",
      "\n",
      "2. **Technology Stack**:\n",
      "   - Microsoft Fabric for data management and analytics.\n",
      "   - Azure cloud services for hosting and scalability.\n",
      "   - Integration with Applied Epic SOAP for policy data retrieval.\n",
      "   - Okta for user authentication.\n",
      "\n",
      "3. **Deployment and Maintenance**:\n",
      "   - CI/CD pipelines for seamless deployment.\n",
      "   - Monitoring and alert systems for proactive issue resolution.\n",
      "   - High availability and disaster recovery mechanisms.\n",
      "\n",
      "4. **Compliance and Security**:\n",
      "   - Adherence to GDPR, CCPA, and HIPAA regulations.\n",
      "   - Encryption of data at rest and in transit.\n",
      "   - Role-based access control and auditing.\n",
      "\n",
      "5. **Stakeholder Engagement**:\n",
      "   - Regular status updates and feedback sessions.\n",
      "   - Workshops for requirements gathering and design reviews.\n",
      "\n",
      "---\n",
      "\n",
      "## **Stakeholders and Audiences**\n",
      "\n",
      "### **Primary Stakeholders**:\n",
      "- **Assured Partners Leadership**: Responsible for strategic oversight and funding.\n",
      "- **Fog Solutions Team**: Implementation partner providing technical expertise.\n",
      "- **AP Business Teams**: End-users of the solution, including brokers and claims associates.\n",
      "\n",
      "### **Secondary Stakeholders**:\n",
      "- **IT Teams**: Responsible for infrastructure setup and maintenance.\n",
      "- **Compliance Officers**: Ensure adherence to data protection and privacy regulations.\n",
      "- **Customers**: Indirect beneficiaries of improved brokerage services.\n",
      "\n",
      "---\n",
      "\n",
      "## **Solution Design Overview**\n",
      "\n",
      "The \"Broker in a Box\" solution is designed to be a modular, scalable, and secure platform. It employs a medallion architecture for data management, with distinct layers for raw (bronze), cleaned (silver), and curated (gold) data. The solution integrates seamlessly with existing AP systems and third-party services, ensuring minimal disruption to current workflows.\n",
      "\n",
      "### **Key Components**:\n",
      "1. **Data Ingestion Layer**:\n",
      "   - Fabric Data Factory pipelines for orchestrating data ingestion.\n",
      "   - Integration with APIs, SQL databases, and CSV files.\n",
      "\n",
      "2. **Data Management Layer**:\n",
      "   - Fabric Lakehouse for centralized data storage.\n",
      "   - Metadata-driven ingestion framework for flexibility and scalability.\n",
      "\n",
      "3. **Application Layer**:\n",
      "   - Frontend and backend components built using Angular and C#.\n",
      "   - Dockerized deployment for portability and consistency.\n",
      "\n",
      "4. **Security Layer**:\n",
      "   - Azure Key Vault for managing sensitive credentials.\n",
      "   - Role-based access control and auditing.\n",
      "\n",
      "---\n",
      "\n",
      "## **User Roles and Security Considerations**\n",
      "\n",
      "### **Security Best Practices**:\n",
      "- **Role-Based Access Control (RBAC)**: Restrict access to data and features based on user roles.\n",
      "- **Data Encryption**: Encrypt data at rest using FIPS 140-2 compliant methods and in transit using TLS 1.2/1.3.\n",
      "- **Audit Trails**: Maintain logs of user activities for compliance and troubleshooting.\n",
      "\n",
      "### **Potential Risks**:\n",
      "- Unauthorized access to sensitive data.\n",
      "- Data breaches due to inadequate encryption.\n",
      "- Misuse of AI-generated recommendations.\n",
      "\n",
      "---\n",
      "\n",
      "## **Definition of User Roles**\n",
      "\n",
      "1. **System Administrators**:\n",
      "   - Manage infrastructure and deployments.\n",
      "   - Monitor system performance and security.\n",
      "\n",
      "2. **Brokers**:\n",
      "   - Access policy data and AI recommendations.\n",
      "   - Perform rule-based policy reviews.\n",
      "\n",
      "3. **Claims Associates**:\n",
      "   - Engage in policy chat sessions for claims processing.\n",
      "   - Collaborate with brokers on policy-related queries.\n",
      "\n",
      "4. **Developers**:\n",
      "   - Develop and maintain application features.\n",
      "   - Implement CI/CD pipelines and resolve issues.\n",
      "\n",
      "5. **Compliance Officers**:\n",
      "   - Monitor adherence to data protection regulations.\n",
      "   - Review audit logs and security reports.\n",
      "\n",
      "---\n",
      "\n",
      "## **Data Sources and Ingestion**\n",
      "\n",
      "### **Data Sources**:\n",
      "- **Applied Epic SOAP**: For policy data retrieval.\n",
      "- **SQL Databases**: For structured data storage.\n",
      "- **APIM and Logic Apps**: For API-based data ingestion.\n",
      "\n",
      "### **Data Ingestion Strategy**:\n",
      "- Use Fabric Data Factory pipelines for orchestrating data ingestion.\n",
      "- Leverage metadata-driven frameworks for flexibility.\n",
      "- Perform daily data ingestion to ensure up-to-date information.\n",
      "\n",
      "---\n",
      "\n",
      "## **Data Storage and Management**\n",
      "\n",
      "### **Storage Solutions**:\n",
      "- **Fabric Lakehouse**: Centralized storage for all data layers.\n",
      "- **OneLake**: Azure ADLS Gen2-based storage for scalability and security.\n",
      "\n",
      "### **Data Retention and Archival Policies**:\n",
      "- Retain raw data for 90 days in the bronze layer.\n",
      "- Archive curated data in the gold layer for up to 7 years.\n",
      "\n",
      "---\n",
      "\n",
      "## **Data Encryption and Data Security**\n",
      "\n",
      "### **Encryption Methods**:\n",
      "- **At Rest**: FIPS 140-2 compliant encryption using Microsoft-managed keys.\n",
      "- **In Transit**: TLS 1.2/1.3 for secure data transmission.\n",
      "\n",
      "### **Data Security Techniques**:\n",
      "- Use Azure Key Vault for managing credentials.\n",
      "- Implement Row-Level Security (RLS) for departmental data segregation.\n",
      "\n",
      "---\n",
      "\n",
      "## **Analytics and Reporting**\n",
      "\n",
      "### **Reporting**:\n",
      "- Use Power BI for interactive dashboards and reports.\n",
      "- Generate daily and monthly reports for policy reviews and AI recommendations.\n",
      "\n",
      "### **Analytics Services**:\n",
      "- Leverage Fabric Notebooks for data engineering and analysis.\n",
      "- Use AI models for generating actionable insights.\n",
      "\n",
      "---\n",
      "\n",
      "## **DevOps Integration**\n",
      "\n",
      "### **Source Control Management**:\n",
      "- Use Azure DevOps Repos for version control.\n",
      "- Implement branching strategies for feature development and bug fixes.\n",
      "\n",
      "### **Code Deployment and Management Processes**:\n",
      "- Use CI/CD pipelines for automated deployments.\n",
      "- Perform smoke tests post-deployment to ensure functionality.\n",
      "\n",
      "### **Rollback Strategies**:\n",
      "- Use Delta Time Travel for data rollback.\n",
      "- Revert code changes using Azure DevOps branch reversion.\n",
      "\n",
      "---\n",
      "\n",
      "## **Cloud Fundamentals/Readiness**\n",
      "\n",
      "### **Regional Planning and Data Center Utilization**:\n",
      "- Deploy resources in Azure regions closest to major AP offices.\n",
      "- Use availability zones for high availability.\n",
      "\n",
      "### **Network and Infrastructure Setup**:\n",
      "- Use Azure Virtual Network for secure communication.\n",
      "- Implement Azure Firewall for traffic filtering.\n",
      "\n",
      "---\n",
      "\n",
      "## **Cost Optimization and Governance**\n",
      "\n",
      "- Use Azure Cost Management for monitoring expenses.\n",
      "- Implement tagging policies for resource tracking.\n",
      "\n",
      "---\n",
      "\n",
      "## **Backup and Recovery Solutions**\n",
      "\n",
      "- Use Azure Backup for regular snapshots.\n",
      "- Implement disaster recovery plans with a Recovery Time Objective (RTO) of 4 hours.\n",
      "\n",
      "---\n",
      "\n",
      "## **High Availability/Disaster Recovery Plan**\n",
      "\n",
      "- Deploy resources across multiple availability zones.\n",
      "- Use Azure Site Recovery for failover capabilities.\n",
      "\n",
      "---\n",
      "\n",
      "## **Monitoring and Alert Systems**\n",
      "\n",
      "- Use Azure Monitor for tracking metrics and logs.\n",
      "- Set up alerts for critical issues such as downtime or security breaches.\n",
      "\n",
      "---\n",
      "\n",
      "## **Appendix and References**\n",
      "\n",
      "### **Glossary of Terms**:\n",
      "- **RBAC**: Role-Based Access Control.\n",
      "- **RLS**: Row-Level Security.\n",
      "- **CI/CD**: Continuous Integration/Continuous Deployment.\n",
      "\n",
      "### **Reference Documents**:\n",
      "- \"AP - Production Release Required Materials\"\n",
      "- \"Broker in a Box - SOP\"\n",
      "- \"Assured Partners - Fog Solutions - Broker in a Box - SOW\"\n",
      "\n",
      "---\n",
      "\n",
      "## **References**\n",
      "\n",
      "- Microsoft Fabric Documentation. Retrieved from https://learn.microsoft.com/en-us/fabric/\n",
      "- Azure DevOps Documentation. Retrieved from https://learn.microsoft.com/en-us/azure/devops/\n",
      "- Azure Key Vault Documentation. Retrieved from https://learn.microsoft.com/en-us/azure/key-vault/\n",
      "- Source: ./my-docs/Broker In A Box/Delivery/AP - Production Release Required Materials/SOP - Broker in a Box - FOG DRAFT - 120924.docx\n",
      "- Source: ./my-docs/Broker In A Box/Proposal & Contracts/AssuredPartners - Fog Solutions - Broker in a Box - AP Formated SOW - Fully Executed.pdf\n",
      "- Source: ./my-docs/Broker In A Box/Delivery/Status updates/Assured Partners - Broker in a Box Sprint 10 Mid-Sprint - 022125.pptx\n"
     ]
    }
   ],
   "source": [
    "#await researcher.write_introduction()\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create langchain retreiver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "systems, offering features like policy project management, document uploads, and tailored natural language queries.  • Broker in a Box provides actionable insights that inform strategic decisions, helping AssuredPartners identify trends, optimize offerings, and enhance customer retention.\n",
      "systems, offering features like policy project management, document uploads, and tailored natural language queries.  • Broker in a Box provides actionable insights that inform strategic decisions, helping AssuredPartners identify trends, optimize offerings, and enhance customer retention.\n",
      "With 7,000 brokers managing 9,000 policies per year, 'Broker in a Box' is a breakthrough. It’s cutting review time by days and will save thousands of hours a year—unlocking speed & precision we’ve never seen before. This is the future of client service at AP & Gallagher!\n",
      "\n",
      "Rob Roth, EVP – Wholesale Brokerage\u000bAccretive Insurance Solutions\n",
      "\n",
      "Challenge: \u000bAP had a time consuming & inconsistent process for reviewing terms details on new policies and renewals.  This is highly dependent on an individual broker’s experience and knowledge of best practices.\n",
      "\n",
      "“\n",
      "\n",
      "”\n",
      "With 7,000 brokers managing 9,000 policies per year, 'Broker in a Box' is a breakthrough. It’s cutting review time by days and will save thousands of hours a year—unlocking speed & precision we’ve never seen before. This is the future of client service at AP & Gallagher!\n",
      "\n",
      "Rob Roth, EVP – Wholesale Brokerage\u000bAssuredPartners, Insurance Solutions\n",
      "\n",
      "”\n",
      "\n",
      "The Power of Specialized AI for Brokers\n",
      "\n",
      "Broker in a Box (Custom AI App)\u000bTailored intelligence, expertise & efficiency for brokers\u000b                                     M365 Copilot, ChatGPT\u000bFoundation for general inquiries\n",
      "\n",
      "Automated, Specialized, Actionable  Repetitive, Time-Consuming, Generalized\n",
      "\n",
      "Step 1: Select from AMS or upload policy\n",
      "\n",
      "Step 2: Hundreds of pre-configured rules and SME intelligence applied instantly\n",
      "\n",
      "Step 3: Auto-generated insights and compliance-checked outputs\n",
      "\n",
      "Step 1: Upload policy document, one at a time\u000b\u000b\n",
      "\n",
      "Step 2: Prompts only as good as user, one at a time\u000b\u000b\n",
      "\n",
      "Step 3: Extract information one query at a time\n"
     ]
    }
   ],
   "source": [
    "new_vector_store = FAISS.load_local(\"faiss_index\", embeddings, allow_dangerous_deserialization=True)\n",
    "retriever = new_vector_store.as_retriever()\n",
    "query = \"What is broker in a box?\"\n",
    "\n",
    "\n",
    "# Process and use the results as needed\n",
    "for result in results:\n",
    "    print(result.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to generate by section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table of Contents\n",
      "1. Project Summary\n",
      "Scope of the Solution\n",
      "Stakeholders and Audiences\n",
      "2. Solution Design Overview\n",
      "2.1 Solution Objective\n",
      "2.2 Current State Solution Diagram\n",
      "2.3 Future State Solution Architecture\n",
      "3. User Roles and Security Considerations\n",
      "3.1 Definition of User Roles\n",
      "4. Data Sources and Ingestion\n",
      "4.1 Identification of Data Sources\n",
      "4.2 Data Ingestion Strategy\n",
      "4.3 Data Ingestion Metadata Framework\n",
      "Ingestion Metadata \n",
      "4.3.1.1 Source Table  \n",
      "4.3.1.2 Source Object Table\n",
      "4.3.1.3 Object Fields Table\n",
      "4.3.2 Data Quality Metadata\n",
      "5. Data Storage and Management\n",
      "5.1 Storage Solutions \n",
      "5.2 Data Organization and Structuring\n",
      "5.3 Common Data Model\n",
      "6. Data Encryption and Security\n",
      "Encryption Methods \n",
      "6.2 Data Security Techniques\n",
      "7. Analytics and Reporting \n",
      "7.1 Analytics Platform\n",
      "7.3 Fabric Domains\n",
      "7.4 Fabric Workspaces\n",
      "7.5 Reporting\n",
      "7.5.1 Legacy Production Reports\n",
      "7.5.2 New Product Dashboard Reporting\n",
      "7.5.3 Operational Data Platform Health\n",
      "7.6 Analytics Services \n",
      "8. DevOps Integration\n",
      "8.1 Source Control Management \n",
      "8.2 Code Deployment and Management Processes\n",
      "8.3 Backward Compatibility Strategies\n",
      "9. Cloud Fundamentals/Readiness Recommendations\n",
      "9.1 Azure Region\n",
      "9.2 Networking\n",
      "9.3 Identity and Role-Based Access Control\n",
      "9.4 Cost Optimization and Cost Governance\n",
      "9.5 High Availability/Disaster Recovery\n",
      "9.6 Compliance\n",
      "9.6 Monitoring and Alerting\n",
      "content=\"The document outlines a comprehensive solution design for implementing a centralized data platform using Microsoft Fabric to support an organization's growing analytical and reporting needs. It emphasizes creating a scalable Lakehouse architecture to unify data ingestion, transformation, and reporting while reducing silos and redundant efforts across business units. The solution integrates diverse data sources, leverages a medallion architecture (Bronze, Silver, Gold layers), and employs metadata-driven frameworks for efficient data ingestion and processing. Key platforms include OneLake for storage, Fabric Data Factory for orchestration, and Power BI for visualization, with a focus on establishing a Common Data Model (CDM) for cross-business-unit reporting. The design incorporates security measures like Azure Key Vault, role-based access controls, and encryption protocols, although some advanced security features (e.g., private endpoints, RLS) are deferred for later phases. Operational health monitoring, DevOps processes, and cost optimization strategies are integral to the implementation, with phased recommendations for scaling, compliance, and disaster recovery as adoption increases. The document also includes recommendations for future enhancements, such as Azure Purview for data classification, Data Loss Prevention, and more robust monitoring through Azure Log Analytics.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 233, 'prompt_tokens': 8967, 'total_tokens': 9200, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b705f0c291', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}} id='run-d2733253-04d2-44a9-9351-cc60f2bab475-0' usage_metadata={'input_tokens': 8967, 'output_tokens': 233, 'total_tokens': 9200, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "content=\"The document outlines a comprehensive solution design for implementing a centralized data platform using Microsoft Fabric to support an organization's growing analytical and reporting needs. It emphasizes creating a scalable Lakehouse architecture to unify data ingestion, transformation, and reporting while reducing silos and redundant efforts across business units. The solution integrates diverse data sources, leverages a medallion architecture (Bronze, Silver, Gold layers), and employs metadata-driven frameworks for efficient data ingestion and processing. Key platforms include OneLake for storage, Fabric Data Factory for orchestration, and Power BI for visualization, with a focus on establishing a Common Data Model (CDM) for cross-business-unit reporting. The design incorporates security measures like Azure Key Vault, role-based access controls, and encryption protocols, although some advanced security features (e.g., private endpoints, RLS) are deferred for later phases. Operational health monitoring, DevOps processes, and cost optimization strategies are integral to the implementation, with phased recommendations for scaling, compliance, and disaster recovery as adoption increases. The document also includes recommendations for future enhancements, such as Azure Purview for data classification, Data Loss Prevention, and more robust monitoring through Azure Log Analytics.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 233, 'prompt_tokens': 8967, 'total_tokens': 9200, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b705f0c291', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}} id='run-d2733253-04d2-44a9-9351-cc60f2bab475-0' usage_metadata={'input_tokens': 8967, 'output_tokens': 233, 'total_tokens': 9200, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "\n",
    "from langchain_openai import AzureOpenAI, AzureChatOpenAI\n",
    "import os\n",
    "\n",
    "def print_headings(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    for paragraph in doc.paragraphs:\n",
    "        if paragraph.style.name.startswith('Heading'):\n",
    "            print(paragraph.text)\n",
    "\n",
    "# Replace 'your_document.docx' with the path to your .docx file\n",
    "print_headings('./my-docs/Amynta Group - Solution Design.docx')\n",
    "\n",
    "\n",
    "# Initialize the Azure OpenAI model\n",
    "\n",
    "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "deployment_name = 'gpt-4o' #os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "model_name = 'gpt-4o' #os.getenv(\"AZURE_OPENAI_MODEL_NAME\")\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    api_key=api_key,\n",
    "    deployment_name=deployment_name,\n",
    "    model_name=model_name,\n",
    "    base_url=os.getenv(\"AZURE_OPENAI_BASE_URL\"),\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The document outlines a comprehensive solution design for a scalable enterprise data platform leveraging Microsoft Fabric to centralize and unify data management, reporting, and analytics across an organization. It details the implementation of a Lakehouse architecture using a medallion model (Bronze, Silver, Gold layers) for data ingestion, transformation, and storage, while employing metadata-driven frameworks to streamline data processing and ensure scalability. The design integrates various data sources, implements secure data handling with Azure Key Vault, and emphasizes governance through role-based access controls (RBAC) and DevOps best practices. Reporting capabilities are powered by Power BI, supported by semantic models and calculation groups to enable efficient report development and operational monitoring. The solution incorporates cost optimization strategies, modular pipelines for processing, and recommendations for future enhancements, such as Azure Landing Zone deployment, private endpoints, and disaster recovery configurations. While the initial phase focuses on non-sensitive operational data, the design anticipates future adoption of compliance measures for sensitive data. The document also highlights governance mechanisms, capacity monitoring, and DevOps integration to ensure a robust, maintainable, and high-performing analytics platform.\n"
     ]
    }
   ],
   "source": [
    "# Summarize the docx content\n",
    "# def summarize_docx(docx_path):\n",
    "#     doc = Document(docx_path)\n",
    "#     full_text = []\n",
    "#     for paragraph in doc.paragraphs:\n",
    "#         full_text.append(paragraph.text)\n",
    "#     document_text = '\\n'.join(full_text)\n",
    "    \n",
    "#     summary_query = f\"Summarize the following document and return a paragraph that can be used as context for other prompts to help produce a document just like it.  Remove any company names.  Do not format in sections.  You MUST return only an overall summary of what hte document is:\\n\\n{document_text}\"\n",
    "#     summary = llm.invoke(summary_query)\n",
    "#     return summary\n",
    "\n",
    "# # Replace 'your_document.docx' with the path to your .docx file\n",
    "# summary = summarize_docx('./my-docs/Amynta Group - Solution Design.docx')\n",
    "# print(summary)\n",
    "\n",
    "# Create the agent using the FAISS index\n",
    "#agent = create_openai_agent(llm, retriever)\n",
    "\n",
    "# Example query to the agent\n",
    "#response = agent.run(\"What is broker in a box?\")\n",
    "print(summary.content)\n",
    "context = summary.content\n",
    "\n",
    "prompt = f\"\"\"\n",
    "    You are to create a design document that describes, in detail, a solutions design for Assured Partners Broker in a box.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
